Epoch 1: train_loss=1.0989, val_loss=1.0978, val_acc=0.4660
Epoch 2: train_loss=1.0938, val_loss=1.0979, val_acc=0.4760
Epoch 3: train_loss=1.0886, val_loss=1.0954, val_acc=0.3460
Epoch 4: train_loss=1.0786, val_loss=1.0926, val_acc=0.2580
Epoch 5: train_loss=1.0719, val_loss=1.0893, val_acc=0.2440
Epoch 6: train_loss=1.0622, val_loss=1.0852, val_acc=0.2900
Epoch 7: train_loss=1.0526, val_loss=1.0801, val_acc=0.3740
Epoch 8: train_loss=1.0421, val_loss=1.0743, val_acc=0.4720
Epoch 9: train_loss=1.0371, val_loss=1.0676, val_acc=0.5620
Epoch 10: train_loss=1.0209, val_loss=1.0603, val_acc=0.6220
Epoch 11: train_loss=1.0105, val_loss=1.0523, val_acc=0.6580
Epoch 12: train_loss=0.9989, val_loss=1.0437, val_acc=0.6980
Epoch 13: train_loss=0.9919, val_loss=1.0345, val_acc=0.7160
Epoch 14: train_loss=0.9819, val_loss=1.0252, val_acc=0.7260
Epoch 15: train_loss=0.9588, val_loss=1.0162, val_acc=0.7340
Epoch 16: train_loss=0.9392, val_loss=1.0072, val_acc=0.7300
Epoch 17: train_loss=0.9362, val_loss=0.9982, val_acc=0.7280
Epoch 18: train_loss=0.9307, val_loss=0.9901, val_acc=0.7320
Epoch 19: train_loss=0.9031, val_loss=0.9822, val_acc=0.7460
Epoch 20: train_loss=0.8818, val_loss=0.9741, val_acc=0.7400
Epoch 21: train_loss=0.8870, val_loss=0.9659, val_acc=0.7400
Epoch 22: train_loss=0.8691, val_loss=0.9578, val_acc=0.7380
Epoch 23: train_loss=0.8366, val_loss=0.9492, val_acc=0.7320
Epoch 24: train_loss=0.8299, val_loss=0.9403, val_acc=0.7400
Epoch 25: train_loss=0.8051, val_loss=0.9314, val_acc=0.7400
Epoch 26: train_loss=0.8110, val_loss=0.9221, val_acc=0.7420
Epoch 27: train_loss=0.7894, val_loss=0.9123, val_acc=0.7440
Epoch 28: train_loss=0.7851, val_loss=0.9021, val_acc=0.7460
Epoch 29: train_loss=0.7606, val_loss=0.8912, val_acc=0.7480
Epoch 30: train_loss=0.7521, val_loss=0.8801, val_acc=0.7500
Epoch 31: train_loss=0.7005, val_loss=0.8688, val_acc=0.7520
Epoch 32: train_loss=0.6833, val_loss=0.8583, val_acc=0.7520
Epoch 33: train_loss=0.7140, val_loss=0.8488, val_acc=0.7540
Epoch 34: train_loss=0.7070, val_loss=0.8398, val_acc=0.7540
Epoch 35: train_loss=0.6575, val_loss=0.8307, val_acc=0.7540
Epoch 36: train_loss=0.6427, val_loss=0.8213, val_acc=0.7560
Epoch 37: train_loss=0.6441, val_loss=0.8126, val_acc=0.7580
Epoch 38: train_loss=0.6393, val_loss=0.8037, val_acc=0.7600
Epoch 39: train_loss=0.6287, val_loss=0.7957, val_acc=0.7600
Epoch 40: train_loss=0.6101, val_loss=0.7875, val_acc=0.7580
Epoch 41: train_loss=0.5461, val_loss=0.7790, val_acc=0.7600
Epoch 42: train_loss=0.6041, val_loss=0.7721, val_acc=0.7600
Epoch 43: train_loss=0.5295, val_loss=0.7659, val_acc=0.7600
Epoch 44: train_loss=0.5375, val_loss=0.7598, val_acc=0.7560
Epoch 45: train_loss=0.5276, val_loss=0.7539, val_acc=0.7580
Epoch 46: train_loss=0.5134, val_loss=0.7484, val_acc=0.7600
Epoch 47: train_loss=0.5187, val_loss=0.7430, val_acc=0.7600
Epoch 48: train_loss=0.4984, val_loss=0.7371, val_acc=0.7620
Epoch 49: train_loss=0.4751, val_loss=0.7311, val_acc=0.7640
Epoch 50: train_loss=0.4858, val_loss=0.7252, val_acc=0.7640
Epoch 51: train_loss=0.4605, val_loss=0.7190, val_acc=0.7680
Epoch 52: train_loss=0.4611, val_loss=0.7123, val_acc=0.7720
Epoch 53: train_loss=0.4456, val_loss=0.7062, val_acc=0.7720
Epoch 54: train_loss=0.4677, val_loss=0.7001, val_acc=0.7760
Epoch 55: train_loss=0.4184, val_loss=0.6941, val_acc=0.7740
Epoch 56: train_loss=0.4175, val_loss=0.6890, val_acc=0.7760
Epoch 57: train_loss=0.4171, val_loss=0.6843, val_acc=0.7760
Epoch 58: train_loss=0.4460, val_loss=0.6806, val_acc=0.7820
Epoch 59: train_loss=0.4235, val_loss=0.6781, val_acc=0.7860
Epoch 60: train_loss=0.3842, val_loss=0.6756, val_acc=0.7780
Epoch 61: train_loss=0.3645, val_loss=0.6728, val_acc=0.7780
Epoch 62: train_loss=0.3818, val_loss=0.6711, val_acc=0.7780
Epoch 63: train_loss=0.3735, val_loss=0.6689, val_acc=0.7780
Epoch 64: train_loss=0.3626, val_loss=0.6667, val_acc=0.7780
Epoch 65: train_loss=0.3410, val_loss=0.6634, val_acc=0.7780
Epoch 66: train_loss=0.3504, val_loss=0.6588, val_acc=0.7800
Epoch 67: train_loss=0.4042, val_loss=0.6540, val_acc=0.7780
Epoch 68: train_loss=0.3448, val_loss=0.6497, val_acc=0.7800
Epoch 69: train_loss=0.3565, val_loss=0.6451, val_acc=0.7800
Epoch 70: train_loss=0.3206, val_loss=0.6412, val_acc=0.7900
Epoch 71: train_loss=0.3022, val_loss=0.6385, val_acc=0.7960
Epoch 72: train_loss=0.2988, val_loss=0.6368, val_acc=0.7960
Epoch 73: train_loss=0.3038, val_loss=0.6359, val_acc=0.7960
Epoch 74: train_loss=0.2952, val_loss=0.6352, val_acc=0.7940
Epoch 75: train_loss=0.3207, val_loss=0.6345, val_acc=0.7900
Epoch 76: train_loss=0.3063, val_loss=0.6339, val_acc=0.7860
Epoch 77: train_loss=0.3145, val_loss=0.6326, val_acc=0.7860
Epoch 78: train_loss=0.3258, val_loss=0.6303, val_acc=0.7860
Epoch 79: train_loss=0.3145, val_loss=0.6278, val_acc=0.7840
Epoch 80: train_loss=0.3100, val_loss=0.6249, val_acc=0.7940
Epoch 81: train_loss=0.2781, val_loss=0.6211, val_acc=0.7960
Epoch 82: train_loss=0.2836, val_loss=0.6175, val_acc=0.7960
Epoch 83: train_loss=0.2876, val_loss=0.6140, val_acc=0.7960
Epoch 84: train_loss=0.3170, val_loss=0.6113, val_acc=0.7920
Epoch 85: train_loss=0.3183, val_loss=0.6103, val_acc=0.7900
Epoch 86: train_loss=0.2766, val_loss=0.6106, val_acc=0.7880
Epoch 87: train_loss=0.3052, val_loss=0.6099, val_acc=0.7880
Epoch 88: train_loss=0.2696, val_loss=0.6086, val_acc=0.7900
Epoch 89: train_loss=0.2705, val_loss=0.6075, val_acc=0.7880
Epoch 90: train_loss=0.2573, val_loss=0.6076, val_acc=0.7920
Epoch 91: train_loss=0.2795, val_loss=0.6070, val_acc=0.7960
Epoch 92: train_loss=0.2632, val_loss=0.6059, val_acc=0.7980
Epoch 93: train_loss=0.2797, val_loss=0.6042, val_acc=0.8000
Epoch 94: train_loss=0.2511, val_loss=0.6038, val_acc=0.7960
Epoch 95: train_loss=0.2275, val_loss=0.6016, val_acc=0.8000
Epoch 96: train_loss=0.2510, val_loss=0.6004, val_acc=0.7940
Epoch 97: train_loss=0.2602, val_loss=0.5994, val_acc=0.7900
Epoch 98: train_loss=0.2418, val_loss=0.5976, val_acc=0.7920
Epoch 99: train_loss=0.2352, val_loss=0.5955, val_acc=0.7920
Epoch 100: train_loss=0.2597, val_loss=0.5938, val_acc=0.7940
Epoch 101: train_loss=0.2236, val_loss=0.5937, val_acc=0.7980
Epoch 102: train_loss=0.2563, val_loss=0.5938, val_acc=0.8000
Epoch 103: train_loss=0.2537, val_loss=0.5946, val_acc=0.7940
Epoch 104: train_loss=0.2624, val_loss=0.5952, val_acc=0.7940
Epoch 105: train_loss=0.2505, val_loss=0.5930, val_acc=0.7940
Epoch 106: train_loss=0.2304, val_loss=0.5911, val_acc=0.7980
Epoch 107: train_loss=0.2117, val_loss=0.5896, val_acc=0.8000
Epoch 108: train_loss=0.2388, val_loss=0.5880, val_acc=0.7940
Epoch 109: train_loss=0.2196, val_loss=0.5866, val_acc=0.7960
Epoch 110: train_loss=0.2010, val_loss=0.5866, val_acc=0.7940
Epoch 111: train_loss=0.2159, val_loss=0.5853, val_acc=0.8000
Epoch 112: train_loss=0.2221, val_loss=0.5834, val_acc=0.8000
Epoch 113: train_loss=0.2302, val_loss=0.5817, val_acc=0.8040
Epoch 114: train_loss=0.2302, val_loss=0.5805, val_acc=0.8000
Epoch 115: train_loss=0.2136, val_loss=0.5805, val_acc=0.8000
Epoch 116: train_loss=0.2305, val_loss=0.5802, val_acc=0.8000
Epoch 117: train_loss=0.2269, val_loss=0.5799, val_acc=0.8000
Epoch 118: train_loss=0.2280, val_loss=0.5792, val_acc=0.7980
Epoch 119: train_loss=0.2037, val_loss=0.5796, val_acc=0.8000
Epoch 120: train_loss=0.2422, val_loss=0.5791, val_acc=0.8020
Epoch 121: train_loss=0.1904, val_loss=0.5786, val_acc=0.8060
Epoch 122: train_loss=0.1923, val_loss=0.5773, val_acc=0.8060
Epoch 123: train_loss=0.2193, val_loss=0.5744, val_acc=0.8100
Epoch 124: train_loss=0.2036, val_loss=0.5708, val_acc=0.8040
Epoch 125: train_loss=0.2367, val_loss=0.5690, val_acc=0.8040
Epoch 126: train_loss=0.2060, val_loss=0.5681, val_acc=0.8060
Epoch 127: train_loss=0.2223, val_loss=0.5685, val_acc=0.8060
Epoch 128: train_loss=0.2010, val_loss=0.5706, val_acc=0.8060
Epoch 129: train_loss=0.2156, val_loss=0.5735, val_acc=0.7980
Epoch 130: train_loss=0.1894, val_loss=0.5758, val_acc=0.7980
Epoch 131: train_loss=0.2056, val_loss=0.5767, val_acc=0.8020
Epoch 132: train_loss=0.2006, val_loss=0.5760, val_acc=0.8040
Epoch 133: train_loss=0.2046, val_loss=0.5754, val_acc=0.8040
Epoch 134: train_loss=0.2316, val_loss=0.5740, val_acc=0.8000
Epoch 135: train_loss=0.2193, val_loss=0.5716, val_acc=0.7980
Epoch 136: train_loss=0.1872, val_loss=0.5701, val_acc=0.8000

Final test accuracy: 0.7950
