Epoch 1: train_loss=1.0994, val_loss=1.0978, val_acc=0.4240
Epoch 2: train_loss=1.0931, val_loss=1.0984, val_acc=0.5060
Epoch 3: train_loss=1.0873, val_loss=1.0991, val_acc=0.3880
Epoch 4: train_loss=1.0827, val_loss=1.0980, val_acc=0.2500
Epoch 5: train_loss=1.0733, val_loss=1.0949, val_acc=0.2220
Epoch 6: train_loss=1.0624, val_loss=1.0900, val_acc=0.2540
Epoch 7: train_loss=1.0543, val_loss=1.0843, val_acc=0.3440
Epoch 8: train_loss=1.0499, val_loss=1.0778, val_acc=0.4540
Epoch 9: train_loss=1.0389, val_loss=1.0704, val_acc=0.5380
Epoch 10: train_loss=1.0276, val_loss=1.0627, val_acc=0.5920
Epoch 11: train_loss=1.0169, val_loss=1.0550, val_acc=0.6300
Epoch 12: train_loss=1.0072, val_loss=1.0473, val_acc=0.6760
Epoch 13: train_loss=1.0078, val_loss=1.0398, val_acc=0.6820
Epoch 14: train_loss=0.9790, val_loss=1.0323, val_acc=0.6900
Epoch 15: train_loss=0.9665, val_loss=1.0248, val_acc=0.7080
Epoch 16: train_loss=0.9647, val_loss=1.0176, val_acc=0.7120
Epoch 17: train_loss=0.9492, val_loss=1.0106, val_acc=0.7080
Epoch 18: train_loss=0.9259, val_loss=1.0035, val_acc=0.7100
Epoch 19: train_loss=0.9174, val_loss=0.9956, val_acc=0.7120
Epoch 20: train_loss=0.9099, val_loss=0.9872, val_acc=0.7160
Epoch 21: train_loss=0.8901, val_loss=0.9787, val_acc=0.7240
Epoch 22: train_loss=0.8823, val_loss=0.9704, val_acc=0.7220
Epoch 23: train_loss=0.8895, val_loss=0.9618, val_acc=0.7260
Epoch 24: train_loss=0.8545, val_loss=0.9521, val_acc=0.7300
Epoch 25: train_loss=0.8475, val_loss=0.9421, val_acc=0.7400
Epoch 26: train_loss=0.8143, val_loss=0.9315, val_acc=0.7460
Epoch 27: train_loss=0.8070, val_loss=0.9214, val_acc=0.7460
Epoch 28: train_loss=0.7841, val_loss=0.9113, val_acc=0.7500
Epoch 29: train_loss=0.7883, val_loss=0.9019, val_acc=0.7520
Epoch 30: train_loss=0.7537, val_loss=0.8928, val_acc=0.7520
Epoch 31: train_loss=0.7349, val_loss=0.8840, val_acc=0.7520
Epoch 32: train_loss=0.7171, val_loss=0.8757, val_acc=0.7520
Epoch 33: train_loss=0.7338, val_loss=0.8674, val_acc=0.7520
Epoch 34: train_loss=0.6968, val_loss=0.8587, val_acc=0.7560
Epoch 35: train_loss=0.6868, val_loss=0.8505, val_acc=0.7560
Epoch 36: train_loss=0.6987, val_loss=0.8418, val_acc=0.7540
Epoch 37: train_loss=0.6859, val_loss=0.8338, val_acc=0.7520
Epoch 38: train_loss=0.6516, val_loss=0.8269, val_acc=0.7560
Epoch 39: train_loss=0.6216, val_loss=0.8206, val_acc=0.7600
Epoch 40: train_loss=0.6205, val_loss=0.8142, val_acc=0.7600
Epoch 41: train_loss=0.6476, val_loss=0.8073, val_acc=0.7620
Epoch 42: train_loss=0.6103, val_loss=0.8002, val_acc=0.7640
Epoch 43: train_loss=0.5970, val_loss=0.7932, val_acc=0.7600
Epoch 44: train_loss=0.5749, val_loss=0.7868, val_acc=0.7600
Epoch 45: train_loss=0.5808, val_loss=0.7803, val_acc=0.7580
Epoch 46: train_loss=0.5812, val_loss=0.7738, val_acc=0.7580
Epoch 47: train_loss=0.5499, val_loss=0.7681, val_acc=0.7600
Epoch 48: train_loss=0.5693, val_loss=0.7624, val_acc=0.7600
Epoch 49: train_loss=0.5617, val_loss=0.7570, val_acc=0.7620
Epoch 50: train_loss=0.5036, val_loss=0.7525, val_acc=0.7620
Epoch 51: train_loss=0.5495, val_loss=0.7480, val_acc=0.7640
Epoch 52: train_loss=0.5015, val_loss=0.7436, val_acc=0.7640
Epoch 53: train_loss=0.5049, val_loss=0.7403, val_acc=0.7640
Epoch 54: train_loss=0.5008, val_loss=0.7374, val_acc=0.7660
Epoch 55: train_loss=0.4927, val_loss=0.7345, val_acc=0.7680
Epoch 56: train_loss=0.4689, val_loss=0.7305, val_acc=0.7700
Epoch 57: train_loss=0.4630, val_loss=0.7263, val_acc=0.7720
Epoch 58: train_loss=0.4312, val_loss=0.7214, val_acc=0.7740
Epoch 59: train_loss=0.4535, val_loss=0.7160, val_acc=0.7740
Epoch 60: train_loss=0.4428, val_loss=0.7114, val_acc=0.7720
Epoch 61: train_loss=0.4598, val_loss=0.7073, val_acc=0.7740
Epoch 62: train_loss=0.4562, val_loss=0.7034, val_acc=0.7740
Epoch 63: train_loss=0.3947, val_loss=0.6993, val_acc=0.7760
Epoch 64: train_loss=0.4209, val_loss=0.6954, val_acc=0.7760
Epoch 65: train_loss=0.4081, val_loss=0.6913, val_acc=0.7780
Epoch 66: train_loss=0.3835, val_loss=0.6865, val_acc=0.7760
Epoch 67: train_loss=0.4225, val_loss=0.6826, val_acc=0.7780
Epoch 68: train_loss=0.3729, val_loss=0.6795, val_acc=0.7820
Epoch 69: train_loss=0.3946, val_loss=0.6773, val_acc=0.7840
Epoch 70: train_loss=0.3924, val_loss=0.6749, val_acc=0.7840
Epoch 71: train_loss=0.3715, val_loss=0.6725, val_acc=0.7820
Epoch 72: train_loss=0.3546, val_loss=0.6708, val_acc=0.7840
Epoch 73: train_loss=0.4150, val_loss=0.6697, val_acc=0.7820
Epoch 74: train_loss=0.4023, val_loss=0.6683, val_acc=0.7820
Epoch 75: train_loss=0.3516, val_loss=0.6670, val_acc=0.7800
Epoch 76: train_loss=0.3953, val_loss=0.6652, val_acc=0.7780
Epoch 77: train_loss=0.3567, val_loss=0.6620, val_acc=0.7780
Epoch 78: train_loss=0.3518, val_loss=0.6580, val_acc=0.7840
Epoch 79: train_loss=0.3573, val_loss=0.6544, val_acc=0.7840
Epoch 80: train_loss=0.3644, val_loss=0.6512, val_acc=0.7980
Epoch 81: train_loss=0.3364, val_loss=0.6487, val_acc=0.7860
Epoch 82: train_loss=0.3398, val_loss=0.6466, val_acc=0.7880
Epoch 83: train_loss=0.3424, val_loss=0.6452, val_acc=0.7940
Epoch 84: train_loss=0.3343, val_loss=0.6427, val_acc=0.7920
Epoch 85: train_loss=0.3304, val_loss=0.6403, val_acc=0.7900
Epoch 86: train_loss=0.3462, val_loss=0.6383, val_acc=0.7880
Epoch 87: train_loss=0.3051, val_loss=0.6371, val_acc=0.7900
Epoch 88: train_loss=0.3167, val_loss=0.6371, val_acc=0.7920
Epoch 89: train_loss=0.3005, val_loss=0.6395, val_acc=0.7900
Epoch 90: train_loss=0.3339, val_loss=0.6408, val_acc=0.7840
Epoch 91: train_loss=0.2942, val_loss=0.6397, val_acc=0.7820
Epoch 92: train_loss=0.2966, val_loss=0.6376, val_acc=0.7840
Epoch 93: train_loss=0.2671, val_loss=0.6351, val_acc=0.7860
Epoch 94: train_loss=0.3288, val_loss=0.6317, val_acc=0.7880
Epoch 95: train_loss=0.2991, val_loss=0.6298, val_acc=0.7880
Epoch 96: train_loss=0.3012, val_loss=0.6283, val_acc=0.7880
Epoch 97: train_loss=0.3224, val_loss=0.6270, val_acc=0.7900
Epoch 98: train_loss=0.2583, val_loss=0.6250, val_acc=0.7920
Epoch 99: train_loss=0.3162, val_loss=0.6245, val_acc=0.7920
Epoch 100: train_loss=0.3037, val_loss=0.6240, val_acc=0.7940
Epoch 101: train_loss=0.3381, val_loss=0.6214, val_acc=0.7960
Epoch 102: train_loss=0.2823, val_loss=0.6194, val_acc=0.7900
Epoch 103: train_loss=0.2507, val_loss=0.6174, val_acc=0.7920
Epoch 104: train_loss=0.2897, val_loss=0.6147, val_acc=0.7920
Epoch 105: train_loss=0.2363, val_loss=0.6123, val_acc=0.7880
Epoch 106: train_loss=0.2440, val_loss=0.6109, val_acc=0.7880
Epoch 107: train_loss=0.3023, val_loss=0.6103, val_acc=0.7880
Epoch 108: train_loss=0.2293, val_loss=0.6102, val_acc=0.7900
Epoch 109: train_loss=0.2657, val_loss=0.6107, val_acc=0.7860
Epoch 110: train_loss=0.2414, val_loss=0.6117, val_acc=0.7900
Epoch 111: train_loss=0.2403, val_loss=0.6130, val_acc=0.7880
Epoch 112: train_loss=0.2316, val_loss=0.6109, val_acc=0.7880
Epoch 113: train_loss=0.2367, val_loss=0.6083, val_acc=0.7900
Epoch 114: train_loss=0.2258, val_loss=0.6063, val_acc=0.7940
Epoch 115: train_loss=0.2638, val_loss=0.6036, val_acc=0.7920
Epoch 116: train_loss=0.2707, val_loss=0.6016, val_acc=0.8000
Epoch 117: train_loss=0.2398, val_loss=0.5998, val_acc=0.8000
Epoch 118: train_loss=0.2373, val_loss=0.5989, val_acc=0.8000
Epoch 119: train_loss=0.2818, val_loss=0.5986, val_acc=0.8000
Epoch 120: train_loss=0.2116, val_loss=0.5982, val_acc=0.7980
Epoch 121: train_loss=0.2029, val_loss=0.5978, val_acc=0.7980
Epoch 122: train_loss=0.2457, val_loss=0.5976, val_acc=0.7920
Epoch 123: train_loss=0.2621, val_loss=0.5976, val_acc=0.7940
Epoch 124: train_loss=0.2215, val_loss=0.5987, val_acc=0.7960
Epoch 125: train_loss=0.2424, val_loss=0.6009, val_acc=0.7880
Epoch 126: train_loss=0.2387, val_loss=0.6039, val_acc=0.7880
Epoch 127: train_loss=0.2597, val_loss=0.6052, val_acc=0.7820
Epoch 128: train_loss=0.2445, val_loss=0.6030, val_acc=0.7820
Epoch 129: train_loss=0.2265, val_loss=0.5990, val_acc=0.7860
Epoch 130: train_loss=0.2269, val_loss=0.5946, val_acc=0.7900
Epoch 131: train_loss=0.2245, val_loss=0.5907, val_acc=0.7940
Epoch 132: train_loss=0.2224, val_loss=0.5888, val_acc=0.7940
Epoch 133: train_loss=0.2179, val_loss=0.5879, val_acc=0.7960
Epoch 134: train_loss=0.2280, val_loss=0.5881, val_acc=0.7960
Epoch 135: train_loss=0.2192, val_loss=0.5890, val_acc=0.7980
Epoch 136: train_loss=0.1961, val_loss=0.5897, val_acc=0.7940
Epoch 137: train_loss=0.2267, val_loss=0.5900, val_acc=0.7920
Epoch 138: train_loss=0.1913, val_loss=0.5889, val_acc=0.7960
Epoch 139: train_loss=0.2257, val_loss=0.5885, val_acc=0.7940
Epoch 140: train_loss=0.2222, val_loss=0.5869, val_acc=0.7960
Epoch 141: train_loss=0.2205, val_loss=0.5842, val_acc=0.7900
Epoch 142: train_loss=0.2003, val_loss=0.5814, val_acc=0.7900
Epoch 143: train_loss=0.1987, val_loss=0.5795, val_acc=0.7860
Epoch 144: train_loss=0.2315, val_loss=0.5791, val_acc=0.7940
Epoch 145: train_loss=0.2003, val_loss=0.5801, val_acc=0.7920
Epoch 146: train_loss=0.2092, val_loss=0.5832, val_acc=0.7980
Epoch 147: train_loss=0.2089, val_loss=0.5850, val_acc=0.7960
Epoch 148: train_loss=0.1847, val_loss=0.5873, val_acc=0.7920
Epoch 149: train_loss=0.1936, val_loss=0.5897, val_acc=0.7900
Epoch 150: train_loss=0.1818, val_loss=0.5903, val_acc=0.7880
Epoch 151: train_loss=0.2435, val_loss=0.5889, val_acc=0.7820
Epoch 152: train_loss=0.1996, val_loss=0.5864, val_acc=0.7900
Epoch 153: train_loss=0.2195, val_loss=0.5826, val_acc=0.7880
Epoch 154: train_loss=0.1926, val_loss=0.5801, val_acc=0.7920

Final test accuracy: 0.7810
