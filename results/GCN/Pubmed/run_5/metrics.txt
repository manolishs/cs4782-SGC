Epoch 1: train_loss=1.0998, val_loss=1.0984, val_acc=0.4760
Epoch 2: train_loss=1.0944, val_loss=1.0980, val_acc=0.4540
Epoch 3: train_loss=1.0884, val_loss=1.0952, val_acc=0.4760
Epoch 4: train_loss=1.0805, val_loss=1.0914, val_acc=0.4800
Epoch 5: train_loss=1.0754, val_loss=1.0863, val_acc=0.4840
Epoch 6: train_loss=1.0680, val_loss=1.0811, val_acc=0.5020
Epoch 7: train_loss=1.0517, val_loss=1.0758, val_acc=0.5460
Epoch 8: train_loss=1.0466, val_loss=1.0705, val_acc=0.5600
Epoch 9: train_loss=1.0329, val_loss=1.0646, val_acc=0.5820
Epoch 10: train_loss=1.0293, val_loss=1.0580, val_acc=0.5960
Epoch 11: train_loss=1.0159, val_loss=1.0508, val_acc=0.6140
Epoch 12: train_loss=1.0053, val_loss=1.0435, val_acc=0.6260
Epoch 13: train_loss=0.9960, val_loss=1.0356, val_acc=0.6360
Epoch 14: train_loss=0.9755, val_loss=1.0271, val_acc=0.6560
Epoch 15: train_loss=0.9625, val_loss=1.0184, val_acc=0.6740
Epoch 16: train_loss=0.9590, val_loss=1.0101, val_acc=0.6960
Epoch 17: train_loss=0.9488, val_loss=1.0011, val_acc=0.7020
Epoch 18: train_loss=0.9226, val_loss=0.9919, val_acc=0.7140
Epoch 19: train_loss=0.9303, val_loss=0.9822, val_acc=0.7200
Epoch 20: train_loss=0.8862, val_loss=0.9719, val_acc=0.7240
Epoch 21: train_loss=0.8863, val_loss=0.9617, val_acc=0.7340
Epoch 22: train_loss=0.8722, val_loss=0.9515, val_acc=0.7400
Epoch 23: train_loss=0.8448, val_loss=0.9415, val_acc=0.7400
Epoch 24: train_loss=0.8432, val_loss=0.9318, val_acc=0.7420
Epoch 25: train_loss=0.8286, val_loss=0.9227, val_acc=0.7400
Epoch 26: train_loss=0.8032, val_loss=0.9138, val_acc=0.7360
Epoch 27: train_loss=0.7856, val_loss=0.9047, val_acc=0.7360
Epoch 28: train_loss=0.7835, val_loss=0.8956, val_acc=0.7420
Epoch 29: train_loss=0.7682, val_loss=0.8863, val_acc=0.7460
Epoch 30: train_loss=0.7574, val_loss=0.8773, val_acc=0.7440
Epoch 31: train_loss=0.7353, val_loss=0.8681, val_acc=0.7480
Epoch 32: train_loss=0.7178, val_loss=0.8590, val_acc=0.7440
Epoch 33: train_loss=0.7220, val_loss=0.8505, val_acc=0.7480
Epoch 34: train_loss=0.6963, val_loss=0.8424, val_acc=0.7480
Epoch 35: train_loss=0.6936, val_loss=0.8340, val_acc=0.7460
Epoch 36: train_loss=0.6492, val_loss=0.8253, val_acc=0.7500
Epoch 37: train_loss=0.6286, val_loss=0.8163, val_acc=0.7500
Epoch 38: train_loss=0.6213, val_loss=0.8075, val_acc=0.7520
Epoch 39: train_loss=0.6573, val_loss=0.7986, val_acc=0.7520
Epoch 40: train_loss=0.6199, val_loss=0.7900, val_acc=0.7500
Epoch 41: train_loss=0.5812, val_loss=0.7816, val_acc=0.7520
Epoch 42: train_loss=0.5885, val_loss=0.7741, val_acc=0.7520
Epoch 43: train_loss=0.5918, val_loss=0.7671, val_acc=0.7520
Epoch 44: train_loss=0.5794, val_loss=0.7608, val_acc=0.7540
Epoch 45: train_loss=0.5504, val_loss=0.7549, val_acc=0.7560
Epoch 46: train_loss=0.5749, val_loss=0.7496, val_acc=0.7640
Epoch 47: train_loss=0.5331, val_loss=0.7441, val_acc=0.7640
Epoch 48: train_loss=0.4787, val_loss=0.7387, val_acc=0.7620
Epoch 49: train_loss=0.5283, val_loss=0.7334, val_acc=0.7620
Epoch 50: train_loss=0.5194, val_loss=0.7282, val_acc=0.7600
Epoch 51: train_loss=0.4983, val_loss=0.7217, val_acc=0.7620
Epoch 52: train_loss=0.4758, val_loss=0.7156, val_acc=0.7620
Epoch 53: train_loss=0.4450, val_loss=0.7099, val_acc=0.7640
Epoch 54: train_loss=0.4415, val_loss=0.7038, val_acc=0.7660
Epoch 55: train_loss=0.4444, val_loss=0.6982, val_acc=0.7640
Epoch 56: train_loss=0.4424, val_loss=0.6921, val_acc=0.7680
Epoch 57: train_loss=0.4322, val_loss=0.6870, val_acc=0.7720
Epoch 58: train_loss=0.4218, val_loss=0.6828, val_acc=0.7720
Epoch 59: train_loss=0.4566, val_loss=0.6788, val_acc=0.7760
Epoch 60: train_loss=0.4243, val_loss=0.6752, val_acc=0.7740
Epoch 61: train_loss=0.4039, val_loss=0.6726, val_acc=0.7720
Epoch 62: train_loss=0.4060, val_loss=0.6701, val_acc=0.7820
Epoch 63: train_loss=0.4107, val_loss=0.6695, val_acc=0.7840
Epoch 64: train_loss=0.3852, val_loss=0.6699, val_acc=0.7780
Epoch 65: train_loss=0.3557, val_loss=0.6699, val_acc=0.7740
Epoch 66: train_loss=0.3481, val_loss=0.6675, val_acc=0.7720
Epoch 67: train_loss=0.3617, val_loss=0.6627, val_acc=0.7760
Epoch 68: train_loss=0.3748, val_loss=0.6580, val_acc=0.7780
Epoch 69: train_loss=0.3632, val_loss=0.6522, val_acc=0.7800
Epoch 70: train_loss=0.3522, val_loss=0.6462, val_acc=0.7820
Epoch 71: train_loss=0.3260, val_loss=0.6414, val_acc=0.7840
Epoch 72: train_loss=0.3425, val_loss=0.6369, val_acc=0.7880
Epoch 73: train_loss=0.4092, val_loss=0.6337, val_acc=0.7940
Epoch 74: train_loss=0.4045, val_loss=0.6319, val_acc=0.7960
Epoch 75: train_loss=0.3622, val_loss=0.6318, val_acc=0.7980
Epoch 76: train_loss=0.3353, val_loss=0.6329, val_acc=0.7960
Epoch 77: train_loss=0.3314, val_loss=0.6344, val_acc=0.7900
Epoch 78: train_loss=0.3091, val_loss=0.6350, val_acc=0.7780
Epoch 79: train_loss=0.2831, val_loss=0.6344, val_acc=0.7740
Epoch 80: train_loss=0.3065, val_loss=0.6320, val_acc=0.7760
Epoch 81: train_loss=0.2998, val_loss=0.6279, val_acc=0.7860
Epoch 82: train_loss=0.3279, val_loss=0.6235, val_acc=0.7900
Epoch 83: train_loss=0.2977, val_loss=0.6192, val_acc=0.7900
Epoch 84: train_loss=0.3001, val_loss=0.6158, val_acc=0.7900
Epoch 85: train_loss=0.3113, val_loss=0.6133, val_acc=0.7940
Epoch 86: train_loss=0.3211, val_loss=0.6116, val_acc=0.7920
Epoch 87: train_loss=0.2786, val_loss=0.6110, val_acc=0.7920
Epoch 88: train_loss=0.2709, val_loss=0.6101, val_acc=0.7940
Epoch 89: train_loss=0.3242, val_loss=0.6096, val_acc=0.7960
Epoch 90: train_loss=0.2828, val_loss=0.6090, val_acc=0.7980
Epoch 91: train_loss=0.2949, val_loss=0.6079, val_acc=0.7960
Epoch 92: train_loss=0.2737, val_loss=0.6071, val_acc=0.7880
Epoch 93: train_loss=0.2483, val_loss=0.6054, val_acc=0.7920
Epoch 94: train_loss=0.2746, val_loss=0.6040, val_acc=0.7900
Epoch 95: train_loss=0.2822, val_loss=0.6028, val_acc=0.7920
Epoch 96: train_loss=0.2664, val_loss=0.6017, val_acc=0.7900
Epoch 97: train_loss=0.2571, val_loss=0.6011, val_acc=0.7900
Epoch 98: train_loss=0.2379, val_loss=0.6000, val_acc=0.7900
Epoch 99: train_loss=0.2798, val_loss=0.5997, val_acc=0.7920
Epoch 100: train_loss=0.2670, val_loss=0.6000, val_acc=0.7900
Epoch 101: train_loss=0.2182, val_loss=0.5988, val_acc=0.7880
Epoch 102: train_loss=0.2700, val_loss=0.5980, val_acc=0.7880
Epoch 103: train_loss=0.2574, val_loss=0.5962, val_acc=0.7860
Epoch 104: train_loss=0.2828, val_loss=0.5950, val_acc=0.7900
Epoch 105: train_loss=0.2746, val_loss=0.5928, val_acc=0.7940
Epoch 106: train_loss=0.2654, val_loss=0.5900, val_acc=0.8000
Epoch 107: train_loss=0.2469, val_loss=0.5891, val_acc=0.7960
Epoch 108: train_loss=0.2405, val_loss=0.5883, val_acc=0.7940
Epoch 109: train_loss=0.2640, val_loss=0.5877, val_acc=0.7960
Epoch 110: train_loss=0.2445, val_loss=0.5863, val_acc=0.8020
Epoch 111: train_loss=0.2421, val_loss=0.5851, val_acc=0.8020
Epoch 112: train_loss=0.2389, val_loss=0.5845, val_acc=0.7940
Epoch 113: train_loss=0.2348, val_loss=0.5853, val_acc=0.7900
Epoch 114: train_loss=0.2016, val_loss=0.5865, val_acc=0.7960
Epoch 115: train_loss=0.2229, val_loss=0.5884, val_acc=0.7920
Epoch 116: train_loss=0.2675, val_loss=0.5896, val_acc=0.7900
Epoch 117: train_loss=0.2545, val_loss=0.5890, val_acc=0.7880
Epoch 118: train_loss=0.2560, val_loss=0.5883, val_acc=0.7840
Epoch 119: train_loss=0.2214, val_loss=0.5863, val_acc=0.7880
Epoch 120: train_loss=0.2112, val_loss=0.5836, val_acc=0.7920
Epoch 121: train_loss=0.2636, val_loss=0.5809, val_acc=0.7920
Epoch 122: train_loss=0.2541, val_loss=0.5791, val_acc=0.7940
Epoch 123: train_loss=0.2404, val_loss=0.5785, val_acc=0.7920
Epoch 124: train_loss=0.2153, val_loss=0.5779, val_acc=0.7940
Epoch 125: train_loss=0.2356, val_loss=0.5779, val_acc=0.7900
Epoch 126: train_loss=0.2060, val_loss=0.5787, val_acc=0.7940
Epoch 127: train_loss=0.2272, val_loss=0.5785, val_acc=0.7960
Epoch 128: train_loss=0.2081, val_loss=0.5783, val_acc=0.7940
Epoch 129: train_loss=0.1860, val_loss=0.5774, val_acc=0.7940
Epoch 130: train_loss=0.2190, val_loss=0.5745, val_acc=0.7960
Epoch 131: train_loss=0.2095, val_loss=0.5724, val_acc=0.8000
Epoch 132: train_loss=0.1958, val_loss=0.5718, val_acc=0.7980
Epoch 133: train_loss=0.1889, val_loss=0.5715, val_acc=0.8000
Epoch 134: train_loss=0.2116, val_loss=0.5715, val_acc=0.8000
Epoch 135: train_loss=0.1902, val_loss=0.5718, val_acc=0.7980
Epoch 136: train_loss=0.1928, val_loss=0.5729, val_acc=0.7960
Epoch 137: train_loss=0.2302, val_loss=0.5736, val_acc=0.7980
Epoch 138: train_loss=0.2139, val_loss=0.5741, val_acc=0.7980
Epoch 139: train_loss=0.1948, val_loss=0.5731, val_acc=0.7940
Epoch 140: train_loss=0.2331, val_loss=0.5701, val_acc=0.8000
Epoch 141: train_loss=0.1826, val_loss=0.5664, val_acc=0.7960
Epoch 142: train_loss=0.1899, val_loss=0.5635, val_acc=0.8000
Epoch 143: train_loss=0.1874, val_loss=0.5638, val_acc=0.7980
Epoch 144: train_loss=0.2095, val_loss=0.5646, val_acc=0.8040
Epoch 145: train_loss=0.2071, val_loss=0.5668, val_acc=0.8000
Epoch 146: train_loss=0.1974, val_loss=0.5689, val_acc=0.7940
Epoch 147: train_loss=0.2071, val_loss=0.5696, val_acc=0.7940
Epoch 148: train_loss=0.2512, val_loss=0.5702, val_acc=0.7920
Epoch 149: train_loss=0.1825, val_loss=0.5696, val_acc=0.7920
Epoch 150: train_loss=0.2184, val_loss=0.5684, val_acc=0.7940
Epoch 151: train_loss=0.2006, val_loss=0.5683, val_acc=0.7960
Epoch 152: train_loss=0.2020, val_loss=0.5673, val_acc=0.7920

Final test accuracy: 0.7900
