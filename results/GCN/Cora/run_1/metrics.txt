Epoch 1: train_loss=1.9464, val_loss=1.9456, val_acc=0.0720
Epoch 2: train_loss=1.9404, val_loss=1.9445, val_acc=0.0720
Epoch 3: train_loss=1.9346, val_loss=1.9428, val_acc=0.0840
Epoch 4: train_loss=1.9243, val_loss=1.9407, val_acc=0.1620
Epoch 5: train_loss=1.9184, val_loss=1.9375, val_acc=0.2180
Epoch 6: train_loss=1.9099, val_loss=1.9332, val_acc=0.2700
Epoch 7: train_loss=1.9026, val_loss=1.9282, val_acc=0.3420
Epoch 8: train_loss=1.8889, val_loss=1.9222, val_acc=0.3420
Epoch 9: train_loss=1.8809, val_loss=1.9161, val_acc=0.3240
Epoch 10: train_loss=1.8705, val_loss=1.9097, val_acc=0.3220
Epoch 11: train_loss=1.8587, val_loss=1.9031, val_acc=0.3280
Epoch 12: train_loss=1.8398, val_loss=1.8958, val_acc=0.3320
Epoch 13: train_loss=1.8360, val_loss=1.8884, val_acc=0.3400
Epoch 14: train_loss=1.8166, val_loss=1.8807, val_acc=0.3640
Epoch 15: train_loss=1.8076, val_loss=1.8731, val_acc=0.3780
Epoch 16: train_loss=1.7977, val_loss=1.8655, val_acc=0.3940
Epoch 17: train_loss=1.7844, val_loss=1.8583, val_acc=0.4120
Epoch 18: train_loss=1.7682, val_loss=1.8505, val_acc=0.4460
Epoch 19: train_loss=1.7566, val_loss=1.8419, val_acc=0.4760
Epoch 20: train_loss=1.7370, val_loss=1.8325, val_acc=0.5240
Epoch 21: train_loss=1.7203, val_loss=1.8226, val_acc=0.5840
Epoch 22: train_loss=1.6937, val_loss=1.8122, val_acc=0.6320
Epoch 23: train_loss=1.6882, val_loss=1.8011, val_acc=0.6700
Epoch 24: train_loss=1.6778, val_loss=1.7899, val_acc=0.7020
Epoch 25: train_loss=1.6397, val_loss=1.7784, val_acc=0.7320
Epoch 26: train_loss=1.6251, val_loss=1.7670, val_acc=0.7340
Epoch 27: train_loss=1.6113, val_loss=1.7555, val_acc=0.7360
Epoch 28: train_loss=1.5870, val_loss=1.7435, val_acc=0.7360
Epoch 29: train_loss=1.5626, val_loss=1.7315, val_acc=0.7380
Epoch 30: train_loss=1.5423, val_loss=1.7185, val_acc=0.7420
Epoch 31: train_loss=1.5298, val_loss=1.7058, val_acc=0.7520
Epoch 32: train_loss=1.4920, val_loss=1.6929, val_acc=0.7540
Epoch 33: train_loss=1.4844, val_loss=1.6804, val_acc=0.7560
Epoch 34: train_loss=1.4741, val_loss=1.6681, val_acc=0.7580
Epoch 35: train_loss=1.4412, val_loss=1.6553, val_acc=0.7580
Epoch 36: train_loss=1.4149, val_loss=1.6418, val_acc=0.7620
Epoch 37: train_loss=1.3581, val_loss=1.6269, val_acc=0.7620
Epoch 38: train_loss=1.3605, val_loss=1.6113, val_acc=0.7620
Epoch 39: train_loss=1.3619, val_loss=1.5948, val_acc=0.7760
Epoch 40: train_loss=1.3412, val_loss=1.5788, val_acc=0.7740
Epoch 41: train_loss=1.2883, val_loss=1.5626, val_acc=0.7760
Epoch 42: train_loss=1.2978, val_loss=1.5464, val_acc=0.7780
Epoch 43: train_loss=1.2814, val_loss=1.5309, val_acc=0.7860
Epoch 44: train_loss=1.2336, val_loss=1.5162, val_acc=0.7780
Epoch 45: train_loss=1.2251, val_loss=1.5012, val_acc=0.7800
Epoch 46: train_loss=1.2072, val_loss=1.4858, val_acc=0.7800
Epoch 47: train_loss=1.1929, val_loss=1.4722, val_acc=0.7780
Epoch 48: train_loss=1.1553, val_loss=1.4581, val_acc=0.7800
Epoch 49: train_loss=1.1355, val_loss=1.4435, val_acc=0.7780
Epoch 50: train_loss=1.1195, val_loss=1.4291, val_acc=0.7820
Epoch 51: train_loss=1.0377, val_loss=1.4141, val_acc=0.7820
Epoch 52: train_loss=1.1028, val_loss=1.3994, val_acc=0.7820
Epoch 53: train_loss=1.0232, val_loss=1.3841, val_acc=0.7840
Epoch 54: train_loss=1.0309, val_loss=1.3695, val_acc=0.7820
Epoch 55: train_loss=1.0114, val_loss=1.3565, val_acc=0.7820
Epoch 56: train_loss=0.9953, val_loss=1.3440, val_acc=0.7820
Epoch 57: train_loss=0.9319, val_loss=1.3308, val_acc=0.7820
Epoch 58: train_loss=0.9721, val_loss=1.3182, val_acc=0.7840
Epoch 59: train_loss=0.9775, val_loss=1.3055, val_acc=0.7820
Epoch 60: train_loss=0.9167, val_loss=1.2938, val_acc=0.7800
Epoch 61: train_loss=0.8727, val_loss=1.2819, val_acc=0.7800
Epoch 62: train_loss=0.8909, val_loss=1.2716, val_acc=0.7820
Epoch 63: train_loss=0.8885, val_loss=1.2618, val_acc=0.7820
Epoch 64: train_loss=0.8568, val_loss=1.2521, val_acc=0.7860
Epoch 65: train_loss=0.8170, val_loss=1.2408, val_acc=0.7860
Epoch 66: train_loss=0.8320, val_loss=1.2285, val_acc=0.7880
Epoch 67: train_loss=0.7959, val_loss=1.2153, val_acc=0.7920
Epoch 68: train_loss=0.7855, val_loss=1.2016, val_acc=0.7900
Epoch 69: train_loss=0.7878, val_loss=1.1885, val_acc=0.7880
Epoch 70: train_loss=0.7760, val_loss=1.1765, val_acc=0.7900
Epoch 71: train_loss=0.7471, val_loss=1.1658, val_acc=0.7900
Epoch 72: train_loss=0.7274, val_loss=1.1570, val_acc=0.7900
Epoch 73: train_loss=0.7494, val_loss=1.1476, val_acc=0.7900
Epoch 74: train_loss=0.7393, val_loss=1.1396, val_acc=0.7880
Epoch 75: train_loss=0.6959, val_loss=1.1315, val_acc=0.7860
Epoch 76: train_loss=0.6930, val_loss=1.1230, val_acc=0.7840
Epoch 77: train_loss=0.6700, val_loss=1.1130, val_acc=0.7840
Epoch 78: train_loss=0.6758, val_loss=1.1041, val_acc=0.7880
Epoch 79: train_loss=0.6410, val_loss=1.0940, val_acc=0.7900
Epoch 80: train_loss=0.6709, val_loss=1.0859, val_acc=0.7920
Epoch 81: train_loss=0.6676, val_loss=1.0769, val_acc=0.7940
Epoch 82: train_loss=0.6434, val_loss=1.0688, val_acc=0.7980
Epoch 83: train_loss=0.6466, val_loss=1.0594, val_acc=0.7980
Epoch 84: train_loss=0.6338, val_loss=1.0507, val_acc=0.7920
Epoch 85: train_loss=0.5957, val_loss=1.0441, val_acc=0.7940
Epoch 86: train_loss=0.5947, val_loss=1.0394, val_acc=0.7920
Epoch 87: train_loss=0.6114, val_loss=1.0366, val_acc=0.7920
Epoch 88: train_loss=0.6115, val_loss=1.0359, val_acc=0.7880
Epoch 89: train_loss=0.5848, val_loss=1.0357, val_acc=0.7820
Epoch 90: train_loss=0.5833, val_loss=1.0344, val_acc=0.7840
Epoch 91: train_loss=0.5474, val_loss=1.0305, val_acc=0.7860
Epoch 92: train_loss=0.5792, val_loss=1.0224, val_acc=0.7880
Epoch 93: train_loss=0.5585, val_loss=1.0127, val_acc=0.7880
Epoch 94: train_loss=0.5550, val_loss=1.0045, val_acc=0.7880
Epoch 95: train_loss=0.5388, val_loss=0.9975, val_acc=0.7920
Epoch 96: train_loss=0.5275, val_loss=0.9896, val_acc=0.7940
Epoch 97: train_loss=0.4925, val_loss=0.9821, val_acc=0.7920
Epoch 98: train_loss=0.4977, val_loss=0.9762, val_acc=0.7920
Epoch 99: train_loss=0.5095, val_loss=0.9712, val_acc=0.7920
Epoch 100: train_loss=0.5513, val_loss=0.9683, val_acc=0.7940
Epoch 101: train_loss=0.5237, val_loss=0.9683, val_acc=0.7940
Epoch 102: train_loss=0.5279, val_loss=0.9686, val_acc=0.7880
Epoch 103: train_loss=0.5398, val_loss=0.9678, val_acc=0.7940
Epoch 104: train_loss=0.5250, val_loss=0.9657, val_acc=0.7960
Epoch 105: train_loss=0.4976, val_loss=0.9618, val_acc=0.7920
Epoch 106: train_loss=0.5200, val_loss=0.9567, val_acc=0.7960
Epoch 107: train_loss=0.5144, val_loss=0.9537, val_acc=0.7960
Epoch 108: train_loss=0.4815, val_loss=0.9480, val_acc=0.7960
Epoch 109: train_loss=0.4728, val_loss=0.9407, val_acc=0.7980
Epoch 110: train_loss=0.4759, val_loss=0.9335, val_acc=0.8020
Epoch 111: train_loss=0.4667, val_loss=0.9272, val_acc=0.7980
Epoch 112: train_loss=0.4432, val_loss=0.9228, val_acc=0.7960
Epoch 113: train_loss=0.4958, val_loss=0.9217, val_acc=0.7960
Epoch 114: train_loss=0.4653, val_loss=0.9214, val_acc=0.8000
Epoch 115: train_loss=0.4426, val_loss=0.9224, val_acc=0.8000
Epoch 116: train_loss=0.4552, val_loss=0.9238, val_acc=0.8000
Epoch 117: train_loss=0.4595, val_loss=0.9245, val_acc=0.7960
Epoch 118: train_loss=0.4465, val_loss=0.9253, val_acc=0.7980
Epoch 119: train_loss=0.4303, val_loss=0.9238, val_acc=0.7960
Epoch 120: train_loss=0.4454, val_loss=0.9224, val_acc=0.7880
Epoch 121: train_loss=0.4356, val_loss=0.9192, val_acc=0.7900
Epoch 122: train_loss=0.4545, val_loss=0.9124, val_acc=0.7940
Epoch 123: train_loss=0.4358, val_loss=0.9058, val_acc=0.7940
Epoch 124: train_loss=0.4330, val_loss=0.9012, val_acc=0.7940
Epoch 125: train_loss=0.4680, val_loss=0.8975, val_acc=0.7980
Epoch 126: train_loss=0.4105, val_loss=0.8935, val_acc=0.8040
Epoch 127: train_loss=0.4292, val_loss=0.8894, val_acc=0.8060
Epoch 128: train_loss=0.3695, val_loss=0.8859, val_acc=0.8060
Epoch 129: train_loss=0.4183, val_loss=0.8831, val_acc=0.8060
Epoch 130: train_loss=0.4086, val_loss=0.8819, val_acc=0.8040
Epoch 131: train_loss=0.4100, val_loss=0.8845, val_acc=0.8000
Epoch 132: train_loss=0.4165, val_loss=0.8841, val_acc=0.8000
Epoch 133: train_loss=0.4409, val_loss=0.8852, val_acc=0.8040
Epoch 134: train_loss=0.3887, val_loss=0.8833, val_acc=0.7980
Epoch 135: train_loss=0.4032, val_loss=0.8788, val_acc=0.7940
Epoch 136: train_loss=0.4053, val_loss=0.8737, val_acc=0.7980
Epoch 137: train_loss=0.3891, val_loss=0.8682, val_acc=0.7980
Epoch 138: train_loss=0.3848, val_loss=0.8632, val_acc=0.7980
Epoch 139: train_loss=0.3981, val_loss=0.8605, val_acc=0.7960
Epoch 140: train_loss=0.3834, val_loss=0.8607, val_acc=0.7980
Epoch 141: train_loss=0.4255, val_loss=0.8644, val_acc=0.7960
Epoch 142: train_loss=0.3723, val_loss=0.8682, val_acc=0.7920
Epoch 143: train_loss=0.3671, val_loss=0.8707, val_acc=0.8000
Epoch 144: train_loss=0.3944, val_loss=0.8676, val_acc=0.8020
Epoch 145: train_loss=0.3646, val_loss=0.8612, val_acc=0.8020
Epoch 146: train_loss=0.3585, val_loss=0.8534, val_acc=0.8000
Epoch 147: train_loss=0.3773, val_loss=0.8458, val_acc=0.8000
Epoch 148: train_loss=0.3856, val_loss=0.8417, val_acc=0.8060
Epoch 149: train_loss=0.3455, val_loss=0.8408, val_acc=0.8080
Epoch 150: train_loss=0.3909, val_loss=0.8410, val_acc=0.8000
Epoch 151: train_loss=0.3648, val_loss=0.8416, val_acc=0.8000
Epoch 152: train_loss=0.3730, val_loss=0.8419, val_acc=0.7960
Epoch 153: train_loss=0.3650, val_loss=0.8416, val_acc=0.7960
Epoch 154: train_loss=0.3734, val_loss=0.8399, val_acc=0.7980
Epoch 155: train_loss=0.3801, val_loss=0.8385, val_acc=0.7980
Epoch 156: train_loss=0.3556, val_loss=0.8361, val_acc=0.8000
Epoch 157: train_loss=0.3586, val_loss=0.8347, val_acc=0.8020
Epoch 158: train_loss=0.3566, val_loss=0.8330, val_acc=0.8020
Epoch 159: train_loss=0.3532, val_loss=0.8309, val_acc=0.7980
Epoch 160: train_loss=0.3589, val_loss=0.8282, val_acc=0.7980
Epoch 161: train_loss=0.3346, val_loss=0.8280, val_acc=0.7960
Epoch 162: train_loss=0.3312, val_loss=0.8276, val_acc=0.7940
Epoch 163: train_loss=0.3538, val_loss=0.8279, val_acc=0.7920
Epoch 164: train_loss=0.3490, val_loss=0.8251, val_acc=0.7920
Epoch 165: train_loss=0.3662, val_loss=0.8196, val_acc=0.7940
Epoch 166: train_loss=0.3546, val_loss=0.8162, val_acc=0.7980
Epoch 167: train_loss=0.3618, val_loss=0.8136, val_acc=0.7980
Epoch 168: train_loss=0.3708, val_loss=0.8135, val_acc=0.8020
Epoch 169: train_loss=0.3192, val_loss=0.8163, val_acc=0.8000
Epoch 170: train_loss=0.3306, val_loss=0.8177, val_acc=0.8000
Epoch 171: train_loss=0.3434, val_loss=0.8188, val_acc=0.8000
Epoch 172: train_loss=0.3524, val_loss=0.8209, val_acc=0.8000
Epoch 173: train_loss=0.3186, val_loss=0.8222, val_acc=0.8020
Epoch 174: train_loss=0.3807, val_loss=0.8233, val_acc=0.7980
Epoch 175: train_loss=0.3465, val_loss=0.8217, val_acc=0.7960
Epoch 176: train_loss=0.3636, val_loss=0.8178, val_acc=0.7920
Epoch 177: train_loss=0.3513, val_loss=0.8137, val_acc=0.7900
Epoch 178: train_loss=0.3434, val_loss=0.8089, val_acc=0.7940
Epoch 179: train_loss=0.3179, val_loss=0.8039, val_acc=0.7960
Epoch 180: train_loss=0.3209, val_loss=0.7986, val_acc=0.7960
Epoch 181: train_loss=0.3374, val_loss=0.7953, val_acc=0.7980
Epoch 182: train_loss=0.3358, val_loss=0.7945, val_acc=0.7960
Epoch 183: train_loss=0.3266, val_loss=0.7953, val_acc=0.7940
Epoch 184: train_loss=0.3534, val_loss=0.7946, val_acc=0.7940
Epoch 185: train_loss=0.3213, val_loss=0.7940, val_acc=0.7940
Epoch 186: train_loss=0.3068, val_loss=0.7931, val_acc=0.7960
Epoch 187: train_loss=0.3243, val_loss=0.7951, val_acc=0.7960
Epoch 188: train_loss=0.3341, val_loss=0.7983, val_acc=0.7960
Epoch 189: train_loss=0.3421, val_loss=0.7997, val_acc=0.7960
Epoch 190: train_loss=0.2857, val_loss=0.8003, val_acc=0.7940
Epoch 191: train_loss=0.3290, val_loss=0.7992, val_acc=0.7960
Epoch 192: train_loss=0.3321, val_loss=0.7963, val_acc=0.7980
Epoch 193: train_loss=0.3658, val_loss=0.7925, val_acc=0.7940
Epoch 194: train_loss=0.2968, val_loss=0.7891, val_acc=0.7940
Epoch 195: train_loss=0.3084, val_loss=0.7873, val_acc=0.7920
Epoch 196: train_loss=0.3050, val_loss=0.7858, val_acc=0.7960
Epoch 197: train_loss=0.3097, val_loss=0.7837, val_acc=0.7960
Epoch 198: train_loss=0.3172, val_loss=0.7829, val_acc=0.7960
Epoch 199: train_loss=0.3228, val_loss=0.7840, val_acc=0.7960
Epoch 200: train_loss=0.3037, val_loss=0.7852, val_acc=0.7980

Final test accuracy: 0.8150
