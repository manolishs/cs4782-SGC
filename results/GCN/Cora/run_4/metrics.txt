Epoch 1: train_loss=1.9460, val_loss=1.9485, val_acc=0.1100
Epoch 2: train_loss=1.9396, val_loss=1.9467, val_acc=0.1080
Epoch 3: train_loss=1.9313, val_loss=1.9441, val_acc=0.1380
Epoch 4: train_loss=1.9218, val_loss=1.9404, val_acc=0.1860
Epoch 5: train_loss=1.9118, val_loss=1.9366, val_acc=0.2040
Epoch 6: train_loss=1.8994, val_loss=1.9330, val_acc=0.1840
Epoch 7: train_loss=1.8961, val_loss=1.9284, val_acc=0.1740
Epoch 8: train_loss=1.8786, val_loss=1.9232, val_acc=0.1740
Epoch 9: train_loss=1.8670, val_loss=1.9172, val_acc=0.1780
Epoch 10: train_loss=1.8549, val_loss=1.9101, val_acc=0.1820
Epoch 11: train_loss=1.8392, val_loss=1.9026, val_acc=0.1920
Epoch 12: train_loss=1.8338, val_loss=1.8943, val_acc=0.2140
Epoch 13: train_loss=1.8172, val_loss=1.8856, val_acc=0.2400
Epoch 14: train_loss=1.8006, val_loss=1.8770, val_acc=0.2740
Epoch 15: train_loss=1.7895, val_loss=1.8690, val_acc=0.3120
Epoch 16: train_loss=1.7638, val_loss=1.8613, val_acc=0.3440
Epoch 17: train_loss=1.7579, val_loss=1.8537, val_acc=0.3780
Epoch 18: train_loss=1.7360, val_loss=1.8463, val_acc=0.4080
Epoch 19: train_loss=1.7206, val_loss=1.8385, val_acc=0.4380
Epoch 20: train_loss=1.6968, val_loss=1.8303, val_acc=0.4760
Epoch 21: train_loss=1.6737, val_loss=1.8207, val_acc=0.5080
Epoch 22: train_loss=1.6547, val_loss=1.8108, val_acc=0.5520
Epoch 23: train_loss=1.6409, val_loss=1.8003, val_acc=0.5800
Epoch 24: train_loss=1.6156, val_loss=1.7900, val_acc=0.6020
Epoch 25: train_loss=1.6052, val_loss=1.7782, val_acc=0.6240
Epoch 26: train_loss=1.6085, val_loss=1.7664, val_acc=0.6320
Epoch 27: train_loss=1.5595, val_loss=1.7536, val_acc=0.6420
Epoch 28: train_loss=1.5364, val_loss=1.7398, val_acc=0.6560
Epoch 29: train_loss=1.5166, val_loss=1.7263, val_acc=0.6660
Epoch 30: train_loss=1.4919, val_loss=1.7131, val_acc=0.6800
Epoch 31: train_loss=1.4690, val_loss=1.7006, val_acc=0.6900
Epoch 32: train_loss=1.4609, val_loss=1.6890, val_acc=0.6920
Epoch 33: train_loss=1.4342, val_loss=1.6769, val_acc=0.6960
Epoch 34: train_loss=1.4179, val_loss=1.6643, val_acc=0.6940
Epoch 35: train_loss=1.3779, val_loss=1.6515, val_acc=0.7040
Epoch 36: train_loss=1.3714, val_loss=1.6378, val_acc=0.7100
Epoch 37: train_loss=1.3545, val_loss=1.6230, val_acc=0.7120
Epoch 38: train_loss=1.3193, val_loss=1.6068, val_acc=0.7180
Epoch 39: train_loss=1.2786, val_loss=1.5908, val_acc=0.7280
Epoch 40: train_loss=1.2544, val_loss=1.5750, val_acc=0.7280
Epoch 41: train_loss=1.2434, val_loss=1.5581, val_acc=0.7460
Epoch 42: train_loss=1.2415, val_loss=1.5419, val_acc=0.7520
Epoch 43: train_loss=1.2087, val_loss=1.5255, val_acc=0.7560
Epoch 44: train_loss=1.1979, val_loss=1.5096, val_acc=0.7560
Epoch 45: train_loss=1.1626, val_loss=1.4938, val_acc=0.7580
Epoch 46: train_loss=1.1074, val_loss=1.4779, val_acc=0.7580
Epoch 47: train_loss=1.1069, val_loss=1.4633, val_acc=0.7600
Epoch 48: train_loss=1.0904, val_loss=1.4487, val_acc=0.7600
Epoch 49: train_loss=1.1042, val_loss=1.4335, val_acc=0.7620
Epoch 50: train_loss=1.0967, val_loss=1.4184, val_acc=0.7680
Epoch 51: train_loss=1.0642, val_loss=1.4036, val_acc=0.7700
Epoch 52: train_loss=1.0462, val_loss=1.3899, val_acc=0.7720
Epoch 53: train_loss=1.0132, val_loss=1.3758, val_acc=0.7720
Epoch 54: train_loss=0.9838, val_loss=1.3602, val_acc=0.7740
Epoch 55: train_loss=0.9455, val_loss=1.3459, val_acc=0.7720
Epoch 56: train_loss=0.9386, val_loss=1.3334, val_acc=0.7740
Epoch 57: train_loss=0.8815, val_loss=1.3211, val_acc=0.7740
Epoch 58: train_loss=0.8897, val_loss=1.3086, val_acc=0.7720
Epoch 59: train_loss=0.8725, val_loss=1.2953, val_acc=0.7740
Epoch 60: train_loss=0.8600, val_loss=1.2800, val_acc=0.7780
Epoch 61: train_loss=0.8616, val_loss=1.2655, val_acc=0.7800
Epoch 62: train_loss=0.8376, val_loss=1.2522, val_acc=0.7820
Epoch 63: train_loss=0.8218, val_loss=1.2381, val_acc=0.7800
Epoch 64: train_loss=0.7982, val_loss=1.2243, val_acc=0.7840
Epoch 65: train_loss=0.7882, val_loss=1.2113, val_acc=0.7900
Epoch 66: train_loss=0.7696, val_loss=1.1982, val_acc=0.7880
Epoch 67: train_loss=0.7187, val_loss=1.1870, val_acc=0.7860
Epoch 68: train_loss=0.7471, val_loss=1.1786, val_acc=0.7860
Epoch 69: train_loss=0.7126, val_loss=1.1698, val_acc=0.7880
Epoch 70: train_loss=0.7109, val_loss=1.1603, val_acc=0.7880
Epoch 71: train_loss=0.7207, val_loss=1.1504, val_acc=0.7840
Epoch 72: train_loss=0.7074, val_loss=1.1415, val_acc=0.7780
Epoch 73: train_loss=0.6848, val_loss=1.1327, val_acc=0.7820
Epoch 74: train_loss=0.6406, val_loss=1.1220, val_acc=0.7800
Epoch 75: train_loss=0.6462, val_loss=1.1110, val_acc=0.7800
Epoch 76: train_loss=0.6618, val_loss=1.1016, val_acc=0.7800
Epoch 77: train_loss=0.6481, val_loss=1.0923, val_acc=0.7820
Epoch 78: train_loss=0.6069, val_loss=1.0830, val_acc=0.7880
Epoch 79: train_loss=0.6074, val_loss=1.0749, val_acc=0.7880
Epoch 80: train_loss=0.6349, val_loss=1.0681, val_acc=0.7880
Epoch 81: train_loss=0.6103, val_loss=1.0636, val_acc=0.7840
Epoch 82: train_loss=0.5998, val_loss=1.0597, val_acc=0.7880
Epoch 83: train_loss=0.5566, val_loss=1.0565, val_acc=0.7900
Epoch 84: train_loss=0.5952, val_loss=1.0515, val_acc=0.7900
Epoch 85: train_loss=0.5636, val_loss=1.0456, val_acc=0.7900
Epoch 86: train_loss=0.5632, val_loss=1.0392, val_acc=0.7900
Epoch 87: train_loss=0.5517, val_loss=1.0316, val_acc=0.7880
Epoch 88: train_loss=0.5414, val_loss=1.0224, val_acc=0.7880
Epoch 89: train_loss=0.5530, val_loss=1.0132, val_acc=0.7880
Epoch 90: train_loss=0.5243, val_loss=1.0065, val_acc=0.7880
Epoch 91: train_loss=0.4963, val_loss=1.0023, val_acc=0.7880
Epoch 92: train_loss=0.5396, val_loss=0.9981, val_acc=0.7840
Epoch 93: train_loss=0.5253, val_loss=0.9928, val_acc=0.7860
Epoch 94: train_loss=0.5177, val_loss=0.9873, val_acc=0.7860
Epoch 95: train_loss=0.4941, val_loss=0.9805, val_acc=0.7840
Epoch 96: train_loss=0.5145, val_loss=0.9746, val_acc=0.7860
Epoch 97: train_loss=0.5132, val_loss=0.9690, val_acc=0.7920
Epoch 98: train_loss=0.5390, val_loss=0.9658, val_acc=0.7920
Epoch 99: train_loss=0.5124, val_loss=0.9614, val_acc=0.7920
Epoch 100: train_loss=0.4883, val_loss=0.9582, val_acc=0.7920
Epoch 101: train_loss=0.5156, val_loss=0.9569, val_acc=0.7900
Epoch 102: train_loss=0.5062, val_loss=0.9554, val_acc=0.7800
Epoch 103: train_loss=0.5015, val_loss=0.9542, val_acc=0.7800
Epoch 104: train_loss=0.5019, val_loss=0.9508, val_acc=0.7820
Epoch 105: train_loss=0.4715, val_loss=0.9445, val_acc=0.7860
Epoch 106: train_loss=0.4943, val_loss=0.9368, val_acc=0.7920
Epoch 107: train_loss=0.4259, val_loss=0.9288, val_acc=0.7940
Epoch 108: train_loss=0.4167, val_loss=0.9218, val_acc=0.7980
Epoch 109: train_loss=0.4640, val_loss=0.9179, val_acc=0.7960
Epoch 110: train_loss=0.4708, val_loss=0.9172, val_acc=0.7920
Epoch 111: train_loss=0.4314, val_loss=0.9170, val_acc=0.7940
Epoch 112: train_loss=0.4384, val_loss=0.9173, val_acc=0.7940
Epoch 113: train_loss=0.4281, val_loss=0.9186, val_acc=0.7920
Epoch 114: train_loss=0.4361, val_loss=0.9210, val_acc=0.7900
Epoch 115: train_loss=0.4257, val_loss=0.9230, val_acc=0.7920
Epoch 116: train_loss=0.4416, val_loss=0.9215, val_acc=0.7900
Epoch 117: train_loss=0.4416, val_loss=0.9162, val_acc=0.7900
Epoch 118: train_loss=0.4193, val_loss=0.9077, val_acc=0.7900
Epoch 119: train_loss=0.4295, val_loss=0.8982, val_acc=0.7940
Epoch 120: train_loss=0.4019, val_loss=0.8905, val_acc=0.7940
Epoch 121: train_loss=0.4036, val_loss=0.8856, val_acc=0.7940
Epoch 122: train_loss=0.4249, val_loss=0.8843, val_acc=0.7940
Epoch 123: train_loss=0.3825, val_loss=0.8866, val_acc=0.7920
Epoch 124: train_loss=0.4276, val_loss=0.8902, val_acc=0.7880
Epoch 125: train_loss=0.4280, val_loss=0.8937, val_acc=0.7900
Epoch 126: train_loss=0.4281, val_loss=0.8950, val_acc=0.7920
Epoch 127: train_loss=0.3760, val_loss=0.8944, val_acc=0.7880
Epoch 128: train_loss=0.4144, val_loss=0.8913, val_acc=0.7940
Epoch 129: train_loss=0.3853, val_loss=0.8872, val_acc=0.7920
Epoch 130: train_loss=0.3980, val_loss=0.8815, val_acc=0.7940
Epoch 131: train_loss=0.3827, val_loss=0.8755, val_acc=0.7900
Epoch 132: train_loss=0.3891, val_loss=0.8702, val_acc=0.7920
Epoch 133: train_loss=0.3775, val_loss=0.8650, val_acc=0.7920
Epoch 134: train_loss=0.3847, val_loss=0.8615, val_acc=0.7940
Epoch 135: train_loss=0.3829, val_loss=0.8604, val_acc=0.7960
Epoch 136: train_loss=0.3832, val_loss=0.8604, val_acc=0.7940
Epoch 137: train_loss=0.3399, val_loss=0.8588, val_acc=0.7960
Epoch 138: train_loss=0.3686, val_loss=0.8582, val_acc=0.7940
Epoch 139: train_loss=0.3994, val_loss=0.8543, val_acc=0.7980
Epoch 140: train_loss=0.3562, val_loss=0.8521, val_acc=0.7980
Epoch 141: train_loss=0.3784, val_loss=0.8508, val_acc=0.7980
Epoch 142: train_loss=0.4086, val_loss=0.8476, val_acc=0.7980
Epoch 143: train_loss=0.3965, val_loss=0.8477, val_acc=0.8000
Epoch 144: train_loss=0.3630, val_loss=0.8462, val_acc=0.7980
Epoch 145: train_loss=0.3742, val_loss=0.8450, val_acc=0.7960
Epoch 146: train_loss=0.3463, val_loss=0.8436, val_acc=0.7960
Epoch 147: train_loss=0.3490, val_loss=0.8443, val_acc=0.7960
Epoch 148: train_loss=0.3707, val_loss=0.8488, val_acc=0.7860
Epoch 149: train_loss=0.3874, val_loss=0.8541, val_acc=0.7880
Epoch 150: train_loss=0.3657, val_loss=0.8593, val_acc=0.7840
Epoch 151: train_loss=0.3748, val_loss=0.8592, val_acc=0.7860
Epoch 152: train_loss=0.3401, val_loss=0.8546, val_acc=0.7880
Epoch 153: train_loss=0.3365, val_loss=0.8476, val_acc=0.7880
Epoch 154: train_loss=0.3600, val_loss=0.8417, val_acc=0.7880
Epoch 155: train_loss=0.3589, val_loss=0.8350, val_acc=0.7960
Epoch 156: train_loss=0.3335, val_loss=0.8318, val_acc=0.7960
Epoch 157: train_loss=0.3417, val_loss=0.8301, val_acc=0.7980
Epoch 158: train_loss=0.3365, val_loss=0.8320, val_acc=0.7980
Epoch 159: train_loss=0.3410, val_loss=0.8324, val_acc=0.7980
Epoch 160: train_loss=0.3338, val_loss=0.8319, val_acc=0.7960
Epoch 161: train_loss=0.3618, val_loss=0.8314, val_acc=0.7940
Epoch 162: train_loss=0.3240, val_loss=0.8320, val_acc=0.7960
Epoch 163: train_loss=0.3355, val_loss=0.8292, val_acc=0.7980
Epoch 164: train_loss=0.3175, val_loss=0.8276, val_acc=0.7980
Epoch 165: train_loss=0.3038, val_loss=0.8262, val_acc=0.8000
Epoch 166: train_loss=0.3432, val_loss=0.8238, val_acc=0.7960
Epoch 167: train_loss=0.3332, val_loss=0.8227, val_acc=0.7940
Epoch 168: train_loss=0.3270, val_loss=0.8220, val_acc=0.7900
Epoch 169: train_loss=0.3494, val_loss=0.8213, val_acc=0.7900
Epoch 170: train_loss=0.3009, val_loss=0.8227, val_acc=0.7880
Epoch 171: train_loss=0.2892, val_loss=0.8221, val_acc=0.7860
Epoch 172: train_loss=0.3058, val_loss=0.8215, val_acc=0.7900
Epoch 173: train_loss=0.3321, val_loss=0.8204, val_acc=0.7900
Epoch 174: train_loss=0.3250, val_loss=0.8185, val_acc=0.7920
Epoch 175: train_loss=0.2946, val_loss=0.8155, val_acc=0.7960
Epoch 176: train_loss=0.3135, val_loss=0.8114, val_acc=0.7980
Epoch 177: train_loss=0.3031, val_loss=0.8061, val_acc=0.8000
Epoch 178: train_loss=0.3074, val_loss=0.8034, val_acc=0.7980
Epoch 179: train_loss=0.3018, val_loss=0.8000, val_acc=0.8000
Epoch 180: train_loss=0.3685, val_loss=0.8002, val_acc=0.7960
Epoch 181: train_loss=0.3088, val_loss=0.8031, val_acc=0.7960
Epoch 182: train_loss=0.3222, val_loss=0.8040, val_acc=0.7960
Epoch 183: train_loss=0.3295, val_loss=0.8038, val_acc=0.7940
Epoch 184: train_loss=0.3006, val_loss=0.8047, val_acc=0.7940
Epoch 185: train_loss=0.3356, val_loss=0.8056, val_acc=0.7920
Epoch 186: train_loss=0.2811, val_loss=0.8034, val_acc=0.7920
Epoch 187: train_loss=0.2910, val_loss=0.8001, val_acc=0.7920
Epoch 188: train_loss=0.3121, val_loss=0.7989, val_acc=0.7900
Epoch 189: train_loss=0.2806, val_loss=0.7959, val_acc=0.7900
Epoch 190: train_loss=0.3301, val_loss=0.7910, val_acc=0.7940
Epoch 191: train_loss=0.2921, val_loss=0.7853, val_acc=0.7960
Epoch 192: train_loss=0.3297, val_loss=0.7840, val_acc=0.7960
Epoch 193: train_loss=0.3084, val_loss=0.7830, val_acc=0.7960
Epoch 194: train_loss=0.2725, val_loss=0.7842, val_acc=0.7960
Epoch 195: train_loss=0.3033, val_loss=0.7855, val_acc=0.7960
Epoch 196: train_loss=0.3023, val_loss=0.7888, val_acc=0.7960
Epoch 197: train_loss=0.3258, val_loss=0.7944, val_acc=0.7920
Epoch 198: train_loss=0.2898, val_loss=0.7981, val_acc=0.7900
Epoch 199: train_loss=0.2919, val_loss=0.7966, val_acc=0.7960
Epoch 200: train_loss=0.3060, val_loss=0.7896, val_acc=0.7960

Final test accuracy: 0.8070
