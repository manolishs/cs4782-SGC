Epoch 1: train_loss=1.7917, val_loss=1.7893, val_acc=0.3000
Epoch 2: train_loss=1.7872, val_loss=1.7872, val_acc=0.3560
Epoch 3: train_loss=1.7813, val_loss=1.7850, val_acc=0.2900
Epoch 4: train_loss=1.7720, val_loss=1.7832, val_acc=0.2000
Epoch 5: train_loss=1.7636, val_loss=1.7807, val_acc=0.1980
Epoch 6: train_loss=1.7538, val_loss=1.7778, val_acc=0.1980
Epoch 7: train_loss=1.7483, val_loss=1.7749, val_acc=0.2000
Epoch 8: train_loss=1.7353, val_loss=1.7717, val_acc=0.2140
Epoch 9: train_loss=1.7246, val_loss=1.7684, val_acc=0.2200
Epoch 10: train_loss=1.7176, val_loss=1.7649, val_acc=0.2360
Epoch 11: train_loss=1.7031, val_loss=1.7607, val_acc=0.2420
Epoch 12: train_loss=1.6912, val_loss=1.7558, val_acc=0.2620
Epoch 13: train_loss=1.6799, val_loss=1.7508, val_acc=0.2740
Epoch 14: train_loss=1.6634, val_loss=1.7458, val_acc=0.2920
Epoch 15: train_loss=1.6596, val_loss=1.7406, val_acc=0.3300
Epoch 16: train_loss=1.6453, val_loss=1.7354, val_acc=0.3500
Epoch 17: train_loss=1.6347, val_loss=1.7301, val_acc=0.3860
Epoch 18: train_loss=1.6186, val_loss=1.7247, val_acc=0.4240
Epoch 19: train_loss=1.6010, val_loss=1.7192, val_acc=0.4580
Epoch 20: train_loss=1.5813, val_loss=1.7134, val_acc=0.4720
Epoch 21: train_loss=1.5794, val_loss=1.7072, val_acc=0.4840
Epoch 22: train_loss=1.5658, val_loss=1.7007, val_acc=0.4940
Epoch 23: train_loss=1.5442, val_loss=1.6938, val_acc=0.4940
Epoch 24: train_loss=1.5296, val_loss=1.6868, val_acc=0.5180
Epoch 25: train_loss=1.5187, val_loss=1.6797, val_acc=0.5340
Epoch 26: train_loss=1.5000, val_loss=1.6726, val_acc=0.5580
Epoch 27: train_loss=1.4836, val_loss=1.6656, val_acc=0.5920
Epoch 28: train_loss=1.4678, val_loss=1.6589, val_acc=0.5980
Epoch 29: train_loss=1.4443, val_loss=1.6523, val_acc=0.6080
Epoch 30: train_loss=1.4497, val_loss=1.6450, val_acc=0.6140
Epoch 31: train_loss=1.4239, val_loss=1.6374, val_acc=0.6320
Epoch 32: train_loss=1.4095, val_loss=1.6297, val_acc=0.6340
Epoch 33: train_loss=1.4187, val_loss=1.6221, val_acc=0.6380
Epoch 34: train_loss=1.3796, val_loss=1.6148, val_acc=0.6400
Epoch 35: train_loss=1.3480, val_loss=1.6068, val_acc=0.6380
Epoch 36: train_loss=1.3618, val_loss=1.5989, val_acc=0.6380
Epoch 37: train_loss=1.3498, val_loss=1.5906, val_acc=0.6460
Epoch 38: train_loss=1.2866, val_loss=1.5817, val_acc=0.6540
Epoch 39: train_loss=1.3104, val_loss=1.5728, val_acc=0.6540
Epoch 40: train_loss=1.2748, val_loss=1.5631, val_acc=0.6620
Epoch 41: train_loss=1.2610, val_loss=1.5542, val_acc=0.6720
Epoch 42: train_loss=1.2447, val_loss=1.5460, val_acc=0.6720
Epoch 43: train_loss=1.2350, val_loss=1.5366, val_acc=0.6760
Epoch 44: train_loss=1.2000, val_loss=1.5285, val_acc=0.6760
Epoch 45: train_loss=1.1943, val_loss=1.5211, val_acc=0.6740
Epoch 46: train_loss=1.1577, val_loss=1.5132, val_acc=0.6780
Epoch 47: train_loss=1.1940, val_loss=1.5054, val_acc=0.6700
Epoch 48: train_loss=1.1650, val_loss=1.4975, val_acc=0.6660
Epoch 49: train_loss=1.1731, val_loss=1.4897, val_acc=0.6680
Epoch 50: train_loss=1.1496, val_loss=1.4800, val_acc=0.6720
Epoch 51: train_loss=1.0846, val_loss=1.4696, val_acc=0.6740
Epoch 52: train_loss=1.0864, val_loss=1.4589, val_acc=0.6780
Epoch 53: train_loss=1.0785, val_loss=1.4503, val_acc=0.6760
Epoch 54: train_loss=1.0330, val_loss=1.4419, val_acc=0.6780
Epoch 55: train_loss=1.0779, val_loss=1.4343, val_acc=0.6760
Epoch 56: train_loss=1.0441, val_loss=1.4268, val_acc=0.6780
Epoch 57: train_loss=1.0051, val_loss=1.4203, val_acc=0.6780
Epoch 58: train_loss=0.9998, val_loss=1.4137, val_acc=0.6820
Epoch 59: train_loss=1.0098, val_loss=1.4076, val_acc=0.6760
Epoch 60: train_loss=1.0165, val_loss=1.4012, val_acc=0.6800
Epoch 61: train_loss=0.9845, val_loss=1.3932, val_acc=0.6800
Epoch 62: train_loss=0.9709, val_loss=1.3846, val_acc=0.6780
Epoch 63: train_loss=0.9261, val_loss=1.3765, val_acc=0.6800
Epoch 64: train_loss=0.9253, val_loss=1.3685, val_acc=0.6740
Epoch 65: train_loss=0.8827, val_loss=1.3599, val_acc=0.6800
Epoch 66: train_loss=0.9087, val_loss=1.3524, val_acc=0.6800
Epoch 67: train_loss=0.9159, val_loss=1.3454, val_acc=0.6840
Epoch 68: train_loss=0.8899, val_loss=1.3404, val_acc=0.6820
Epoch 69: train_loss=0.9158, val_loss=1.3362, val_acc=0.6760
Epoch 70: train_loss=0.8818, val_loss=1.3340, val_acc=0.6760
Epoch 71: train_loss=0.9070, val_loss=1.3307, val_acc=0.6800
Epoch 72: train_loss=0.8332, val_loss=1.3265, val_acc=0.6780
Epoch 73: train_loss=0.8618, val_loss=1.3197, val_acc=0.6840
Epoch 74: train_loss=0.8079, val_loss=1.3116, val_acc=0.6780
Epoch 75: train_loss=0.8275, val_loss=1.3025, val_acc=0.6720
Epoch 76: train_loss=0.8081, val_loss=1.2953, val_acc=0.6700
Epoch 77: train_loss=0.7879, val_loss=1.2894, val_acc=0.6740
Epoch 78: train_loss=0.7838, val_loss=1.2855, val_acc=0.6800
Epoch 79: train_loss=0.7663, val_loss=1.2820, val_acc=0.6800
Epoch 80: train_loss=0.7650, val_loss=1.2790, val_acc=0.6800
Epoch 81: train_loss=0.7725, val_loss=1.2755, val_acc=0.6800
Epoch 82: train_loss=0.7746, val_loss=1.2695, val_acc=0.6820
Epoch 83: train_loss=0.7671, val_loss=1.2644, val_acc=0.6860
Epoch 84: train_loss=0.7719, val_loss=1.2588, val_acc=0.6820
Epoch 85: train_loss=0.7550, val_loss=1.2518, val_acc=0.6760
Epoch 86: train_loss=0.7428, val_loss=1.2465, val_acc=0.6780
Epoch 87: train_loss=0.7617, val_loss=1.2418, val_acc=0.6800
Epoch 88: train_loss=0.7094, val_loss=1.2366, val_acc=0.6800
Epoch 89: train_loss=0.7402, val_loss=1.2316, val_acc=0.6800
Epoch 90: train_loss=0.6983, val_loss=1.2268, val_acc=0.6820
Epoch 91: train_loss=0.7150, val_loss=1.2238, val_acc=0.6780
Epoch 92: train_loss=0.7287, val_loss=1.2205, val_acc=0.6840
Epoch 93: train_loss=0.6525, val_loss=1.2178, val_acc=0.6840
Epoch 94: train_loss=0.7005, val_loss=1.2144, val_acc=0.6880
Epoch 95: train_loss=0.6724, val_loss=1.2105, val_acc=0.6860
Epoch 96: train_loss=0.6398, val_loss=1.2078, val_acc=0.6920
Epoch 97: train_loss=0.6369, val_loss=1.2048, val_acc=0.6900
Epoch 98: train_loss=0.6439, val_loss=1.2014, val_acc=0.6800
Epoch 99: train_loss=0.6822, val_loss=1.1976, val_acc=0.6800
Epoch 100: train_loss=0.6444, val_loss=1.1933, val_acc=0.6840
Epoch 101: train_loss=0.6572, val_loss=1.1890, val_acc=0.6760
Epoch 102: train_loss=0.6453, val_loss=1.1852, val_acc=0.6800
Epoch 103: train_loss=0.6623, val_loss=1.1814, val_acc=0.6820
Epoch 104: train_loss=0.6081, val_loss=1.1798, val_acc=0.6800
Epoch 105: train_loss=0.6202, val_loss=1.1783, val_acc=0.6780
Epoch 106: train_loss=0.6548, val_loss=1.1766, val_acc=0.6840
Epoch 107: train_loss=0.6673, val_loss=1.1754, val_acc=0.6800
Epoch 108: train_loss=0.6270, val_loss=1.1727, val_acc=0.6800
Epoch 109: train_loss=0.5953, val_loss=1.1709, val_acc=0.6780
Epoch 110: train_loss=0.6030, val_loss=1.1684, val_acc=0.6780
Epoch 111: train_loss=0.6096, val_loss=1.1658, val_acc=0.6800
Epoch 112: train_loss=0.6213, val_loss=1.1610, val_acc=0.6760
Epoch 113: train_loss=0.5894, val_loss=1.1575, val_acc=0.6780
Epoch 114: train_loss=0.5872, val_loss=1.1534, val_acc=0.6800
Epoch 115: train_loss=0.6178, val_loss=1.1497, val_acc=0.6820
Epoch 116: train_loss=0.5791, val_loss=1.1478, val_acc=0.6800
Epoch 117: train_loss=0.5673, val_loss=1.1455, val_acc=0.6840
Epoch 118: train_loss=0.5520, val_loss=1.1441, val_acc=0.6840
Epoch 119: train_loss=0.6151, val_loss=1.1428, val_acc=0.6860
Epoch 120: train_loss=0.6435, val_loss=1.1403, val_acc=0.6860
Epoch 121: train_loss=0.5153, val_loss=1.1375, val_acc=0.6820
Epoch 122: train_loss=0.5504, val_loss=1.1342, val_acc=0.6860
Epoch 123: train_loss=0.5892, val_loss=1.1316, val_acc=0.6960
Epoch 124: train_loss=0.5776, val_loss=1.1291, val_acc=0.6960
Epoch 125: train_loss=0.5374, val_loss=1.1236, val_acc=0.6940
Epoch 126: train_loss=0.5024, val_loss=1.1200, val_acc=0.6980
Epoch 127: train_loss=0.5641, val_loss=1.1188, val_acc=0.6940
Epoch 128: train_loss=0.5484, val_loss=1.1192, val_acc=0.6880
Epoch 129: train_loss=0.4895, val_loss=1.1195, val_acc=0.6880
Epoch 130: train_loss=0.5851, val_loss=1.1194, val_acc=0.6840
Epoch 131: train_loss=0.5777, val_loss=1.1183, val_acc=0.6840
Epoch 132: train_loss=0.4959, val_loss=1.1172, val_acc=0.6840
Epoch 133: train_loss=0.5309, val_loss=1.1141, val_acc=0.6860
Epoch 134: train_loss=0.5362, val_loss=1.1099, val_acc=0.6860
Epoch 135: train_loss=0.5232, val_loss=1.1051, val_acc=0.6980
Epoch 136: train_loss=0.5168, val_loss=1.0996, val_acc=0.6960
Epoch 137: train_loss=0.4666, val_loss=1.0960, val_acc=0.6940
Epoch 138: train_loss=0.5432, val_loss=1.0949, val_acc=0.6960
Epoch 139: train_loss=0.5546, val_loss=1.0972, val_acc=0.6900
Epoch 140: train_loss=0.5354, val_loss=1.0997, val_acc=0.6800
Epoch 141: train_loss=0.4995, val_loss=1.1024, val_acc=0.6800
Epoch 142: train_loss=0.5136, val_loss=1.1055, val_acc=0.6780
Epoch 143: train_loss=0.5205, val_loss=1.1038, val_acc=0.6800
Epoch 144: train_loss=0.5307, val_loss=1.1009, val_acc=0.6820
Epoch 145: train_loss=0.4988, val_loss=1.0972, val_acc=0.6840
Epoch 146: train_loss=0.4792, val_loss=1.0936, val_acc=0.6920
Epoch 147: train_loss=0.5427, val_loss=1.0871, val_acc=0.6980
Epoch 148: train_loss=0.4718, val_loss=1.0817, val_acc=0.7100
Epoch 149: train_loss=0.4986, val_loss=1.0782, val_acc=0.7060
Epoch 150: train_loss=0.4955, val_loss=1.0755, val_acc=0.7060
Epoch 151: train_loss=0.4846, val_loss=1.0741, val_acc=0.7040
Epoch 152: train_loss=0.4896, val_loss=1.0752, val_acc=0.7060
Epoch 153: train_loss=0.5046, val_loss=1.0781, val_acc=0.7000
Epoch 154: train_loss=0.4581, val_loss=1.0797, val_acc=0.6900
Epoch 155: train_loss=0.5178, val_loss=1.0826, val_acc=0.6840
Epoch 156: train_loss=0.4437, val_loss=1.0856, val_acc=0.6820
Epoch 157: train_loss=0.5128, val_loss=1.0856, val_acc=0.6840
Epoch 158: train_loss=0.5111, val_loss=1.0821, val_acc=0.6860
Epoch 159: train_loss=0.5170, val_loss=1.0757, val_acc=0.6920
Epoch 160: train_loss=0.4783, val_loss=1.0722, val_acc=0.6940
Epoch 161: train_loss=0.4505, val_loss=1.0720, val_acc=0.6940
Epoch 162: train_loss=0.4661, val_loss=1.0709, val_acc=0.6980
Epoch 163: train_loss=0.4824, val_loss=1.0691, val_acc=0.6980
Epoch 164: train_loss=0.4898, val_loss=1.0676, val_acc=0.6860
Epoch 165: train_loss=0.4474, val_loss=1.0645, val_acc=0.6860
Epoch 166: train_loss=0.4256, val_loss=1.0630, val_acc=0.6900
Epoch 167: train_loss=0.4186, val_loss=1.0619, val_acc=0.6880
Epoch 168: train_loss=0.4504, val_loss=1.0625, val_acc=0.6900
Epoch 169: train_loss=0.4993, val_loss=1.0655, val_acc=0.6900
Epoch 170: train_loss=0.4452, val_loss=1.0660, val_acc=0.6940
Epoch 171: train_loss=0.4264, val_loss=1.0657, val_acc=0.6980
Epoch 172: train_loss=0.4498, val_loss=1.0635, val_acc=0.6940
Epoch 173: train_loss=0.4612, val_loss=1.0604, val_acc=0.6920
Epoch 174: train_loss=0.4224, val_loss=1.0581, val_acc=0.6880
Epoch 175: train_loss=0.4414, val_loss=1.0566, val_acc=0.6880
Epoch 176: train_loss=0.4304, val_loss=1.0560, val_acc=0.6860
Epoch 177: train_loss=0.4866, val_loss=1.0548, val_acc=0.6900
Epoch 178: train_loss=0.4850, val_loss=1.0550, val_acc=0.6900
Epoch 179: train_loss=0.4623, val_loss=1.0552, val_acc=0.6940
Epoch 180: train_loss=0.4322, val_loss=1.0544, val_acc=0.6960
Epoch 181: train_loss=0.4347, val_loss=1.0530, val_acc=0.6960
Epoch 182: train_loss=0.4246, val_loss=1.0500, val_acc=0.7000
Epoch 183: train_loss=0.4056, val_loss=1.0474, val_acc=0.7000
Epoch 184: train_loss=0.4073, val_loss=1.0476, val_acc=0.6960
Epoch 185: train_loss=0.4298, val_loss=1.0478, val_acc=0.6900
Epoch 186: train_loss=0.4105, val_loss=1.0467, val_acc=0.6900
Epoch 187: train_loss=0.4391, val_loss=1.0445, val_acc=0.6900
Epoch 188: train_loss=0.4122, val_loss=1.0441, val_acc=0.6900
Epoch 189: train_loss=0.4021, val_loss=1.0463, val_acc=0.6900
Epoch 190: train_loss=0.4039, val_loss=1.0492, val_acc=0.6900
Epoch 191: train_loss=0.4265, val_loss=1.0531, val_acc=0.6960
Epoch 192: train_loss=0.4136, val_loss=1.0549, val_acc=0.6960
Epoch 193: train_loss=0.4532, val_loss=1.0519, val_acc=0.6980
Epoch 194: train_loss=0.4076, val_loss=1.0479, val_acc=0.6980
Epoch 195: train_loss=0.3977, val_loss=1.0431, val_acc=0.6940
Epoch 196: train_loss=0.4244, val_loss=1.0386, val_acc=0.6920
Epoch 197: train_loss=0.4072, val_loss=1.0344, val_acc=0.6920
Epoch 198: train_loss=0.4219, val_loss=1.0335, val_acc=0.6900
Epoch 199: train_loss=0.3789, val_loss=1.0364, val_acc=0.6940
Epoch 200: train_loss=0.4380, val_loss=1.0397, val_acc=0.7000

Final test accuracy: 0.6980
