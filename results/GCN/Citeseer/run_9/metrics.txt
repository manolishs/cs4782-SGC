Epoch 1: train_loss=1.7916, val_loss=1.7908, val_acc=0.2780
Epoch 2: train_loss=1.7862, val_loss=1.7909, val_acc=0.2720
Epoch 3: train_loss=1.7784, val_loss=1.7876, val_acc=0.2340
Epoch 4: train_loss=1.7682, val_loss=1.7851, val_acc=0.2340
Epoch 5: train_loss=1.7615, val_loss=1.7828, val_acc=0.2280
Epoch 6: train_loss=1.7531, val_loss=1.7805, val_acc=0.2260
Epoch 7: train_loss=1.7395, val_loss=1.7781, val_acc=0.2280
Epoch 8: train_loss=1.7350, val_loss=1.7750, val_acc=0.2360
Epoch 9: train_loss=1.7240, val_loss=1.7717, val_acc=0.2480
Epoch 10: train_loss=1.7138, val_loss=1.7681, val_acc=0.2580
Epoch 11: train_loss=1.7078, val_loss=1.7636, val_acc=0.2620
Epoch 12: train_loss=1.6866, val_loss=1.7588, val_acc=0.2660
Epoch 13: train_loss=1.6722, val_loss=1.7537, val_acc=0.2900
Epoch 14: train_loss=1.6691, val_loss=1.7482, val_acc=0.3140
Epoch 15: train_loss=1.6596, val_loss=1.7423, val_acc=0.3500
Epoch 16: train_loss=1.6390, val_loss=1.7365, val_acc=0.4020
Epoch 17: train_loss=1.6230, val_loss=1.7310, val_acc=0.4500
Epoch 18: train_loss=1.6196, val_loss=1.7256, val_acc=0.4700
Epoch 19: train_loss=1.5940, val_loss=1.7204, val_acc=0.4940
Epoch 20: train_loss=1.5965, val_loss=1.7147, val_acc=0.5180
Epoch 21: train_loss=1.5791, val_loss=1.7086, val_acc=0.5340
Epoch 22: train_loss=1.5725, val_loss=1.7023, val_acc=0.5440
Epoch 23: train_loss=1.5506, val_loss=1.6956, val_acc=0.5560
Epoch 24: train_loss=1.5350, val_loss=1.6887, val_acc=0.5920
Epoch 25: train_loss=1.5311, val_loss=1.6817, val_acc=0.6100
Epoch 26: train_loss=1.5143, val_loss=1.6746, val_acc=0.6240
Epoch 27: train_loss=1.4916, val_loss=1.6672, val_acc=0.6280
Epoch 28: train_loss=1.4841, val_loss=1.6602, val_acc=0.6320
Epoch 29: train_loss=1.4580, val_loss=1.6529, val_acc=0.6320
Epoch 30: train_loss=1.4574, val_loss=1.6456, val_acc=0.6300
Epoch 31: train_loss=1.4422, val_loss=1.6390, val_acc=0.6380
Epoch 32: train_loss=1.4047, val_loss=1.6328, val_acc=0.6440
Epoch 33: train_loss=1.4059, val_loss=1.6260, val_acc=0.6480
Epoch 34: train_loss=1.3772, val_loss=1.6187, val_acc=0.6520
Epoch 35: train_loss=1.3902, val_loss=1.6111, val_acc=0.6600
Epoch 36: train_loss=1.3612, val_loss=1.6030, val_acc=0.6660
Epoch 37: train_loss=1.3424, val_loss=1.5946, val_acc=0.6680
Epoch 38: train_loss=1.3204, val_loss=1.5862, val_acc=0.6700
Epoch 39: train_loss=1.3184, val_loss=1.5773, val_acc=0.6660
Epoch 40: train_loss=1.3033, val_loss=1.5687, val_acc=0.6640
Epoch 41: train_loss=1.2909, val_loss=1.5600, val_acc=0.6620
Epoch 42: train_loss=1.2796, val_loss=1.5517, val_acc=0.6660
Epoch 43: train_loss=1.2408, val_loss=1.5434, val_acc=0.6680
Epoch 44: train_loss=1.2410, val_loss=1.5344, val_acc=0.6780
Epoch 45: train_loss=1.1942, val_loss=1.5253, val_acc=0.6860
Epoch 46: train_loss=1.1935, val_loss=1.5171, val_acc=0.6840
Epoch 47: train_loss=1.1748, val_loss=1.5092, val_acc=0.6880
Epoch 48: train_loss=1.1451, val_loss=1.5021, val_acc=0.6880
Epoch 49: train_loss=1.1662, val_loss=1.4961, val_acc=0.6880
Epoch 50: train_loss=1.1673, val_loss=1.4903, val_acc=0.6840
Epoch 51: train_loss=1.1181, val_loss=1.4841, val_acc=0.6880
Epoch 52: train_loss=1.1002, val_loss=1.4771, val_acc=0.6920
Epoch 53: train_loss=1.1008, val_loss=1.4679, val_acc=0.6940
Epoch 54: train_loss=1.0534, val_loss=1.4583, val_acc=0.6940
Epoch 55: train_loss=1.0755, val_loss=1.4487, val_acc=0.6940
Epoch 56: train_loss=1.0444, val_loss=1.4382, val_acc=0.7040
Epoch 57: train_loss=1.0282, val_loss=1.4284, val_acc=0.7000
Epoch 58: train_loss=1.0163, val_loss=1.4205, val_acc=0.7040
Epoch 59: train_loss=1.0049, val_loss=1.4141, val_acc=0.7000
Epoch 60: train_loss=0.9809, val_loss=1.4082, val_acc=0.6940
Epoch 61: train_loss=0.9565, val_loss=1.4023, val_acc=0.6980
Epoch 62: train_loss=0.9230, val_loss=1.3962, val_acc=0.6960
Epoch 63: train_loss=1.0010, val_loss=1.3890, val_acc=0.6980
Epoch 64: train_loss=0.9582, val_loss=1.3817, val_acc=0.6960
Epoch 65: train_loss=0.9012, val_loss=1.3730, val_acc=0.7060
Epoch 66: train_loss=0.9231, val_loss=1.3633, val_acc=0.7040
Epoch 67: train_loss=0.8815, val_loss=1.3534, val_acc=0.7120
Epoch 68: train_loss=0.9055, val_loss=1.3453, val_acc=0.7140
Epoch 69: train_loss=0.8944, val_loss=1.3394, val_acc=0.7080
Epoch 70: train_loss=0.8906, val_loss=1.3347, val_acc=0.7060
Epoch 71: train_loss=0.8690, val_loss=1.3309, val_acc=0.6960
Epoch 72: train_loss=0.8546, val_loss=1.3281, val_acc=0.6980
Epoch 73: train_loss=0.8569, val_loss=1.3260, val_acc=0.7060
Epoch 74: train_loss=0.8467, val_loss=1.3232, val_acc=0.7060
Epoch 75: train_loss=0.8208, val_loss=1.3185, val_acc=0.7080
Epoch 76: train_loss=0.8606, val_loss=1.3123, val_acc=0.7020
Epoch 77: train_loss=0.8148, val_loss=1.3042, val_acc=0.7020
Epoch 78: train_loss=0.8380, val_loss=1.2978, val_acc=0.6980
Epoch 79: train_loss=0.7760, val_loss=1.2910, val_acc=0.7000
Epoch 80: train_loss=0.7997, val_loss=1.2838, val_acc=0.7040
Epoch 81: train_loss=0.7657, val_loss=1.2764, val_acc=0.7060
Epoch 82: train_loss=0.7655, val_loss=1.2701, val_acc=0.7100
Epoch 83: train_loss=0.7979, val_loss=1.2641, val_acc=0.7140
Epoch 84: train_loss=0.7711, val_loss=1.2583, val_acc=0.7160
Epoch 85: train_loss=0.7723, val_loss=1.2539, val_acc=0.7160
Epoch 86: train_loss=0.7353, val_loss=1.2511, val_acc=0.7200
Epoch 87: train_loss=0.7731, val_loss=1.2496, val_acc=0.7160
Epoch 88: train_loss=0.7589, val_loss=1.2473, val_acc=0.7160
Epoch 89: train_loss=0.7294, val_loss=1.2456, val_acc=0.7080
Epoch 90: train_loss=0.7271, val_loss=1.2438, val_acc=0.7000
Epoch 91: train_loss=0.7251, val_loss=1.2408, val_acc=0.7000
Epoch 92: train_loss=0.7185, val_loss=1.2364, val_acc=0.7040
Epoch 93: train_loss=0.6932, val_loss=1.2316, val_acc=0.7040
Epoch 94: train_loss=0.6522, val_loss=1.2256, val_acc=0.7060
Epoch 95: train_loss=0.7106, val_loss=1.2204, val_acc=0.7080
Epoch 96: train_loss=0.6919, val_loss=1.2158, val_acc=0.7060
Epoch 97: train_loss=0.6947, val_loss=1.2121, val_acc=0.7060
Epoch 98: train_loss=0.6712, val_loss=1.2067, val_acc=0.7100
Epoch 99: train_loss=0.6156, val_loss=1.2017, val_acc=0.7120
Epoch 100: train_loss=0.6589, val_loss=1.1977, val_acc=0.7120
Epoch 101: train_loss=0.6489, val_loss=1.1957, val_acc=0.7140
Epoch 102: train_loss=0.6935, val_loss=1.1947, val_acc=0.7100
Epoch 103: train_loss=0.6699, val_loss=1.1916, val_acc=0.7080
Epoch 104: train_loss=0.6472, val_loss=1.1888, val_acc=0.7140
Epoch 105: train_loss=0.6091, val_loss=1.1859, val_acc=0.7100
Epoch 106: train_loss=0.6341, val_loss=1.1822, val_acc=0.7100
Epoch 107: train_loss=0.6146, val_loss=1.1780, val_acc=0.7100
Epoch 108: train_loss=0.6576, val_loss=1.1740, val_acc=0.7080
Epoch 109: train_loss=0.6230, val_loss=1.1693, val_acc=0.7120
Epoch 110: train_loss=0.6076, val_loss=1.1667, val_acc=0.7100
Epoch 111: train_loss=0.6386, val_loss=1.1655, val_acc=0.7100
Epoch 112: train_loss=0.5969, val_loss=1.1648, val_acc=0.7060
Epoch 113: train_loss=0.5691, val_loss=1.1639, val_acc=0.7080
Epoch 114: train_loss=0.6192, val_loss=1.1612, val_acc=0.7060
Epoch 115: train_loss=0.6166, val_loss=1.1570, val_acc=0.7060
Epoch 116: train_loss=0.5927, val_loss=1.1522, val_acc=0.7080
Epoch 117: train_loss=0.5792, val_loss=1.1487, val_acc=0.7100
Epoch 118: train_loss=0.6033, val_loss=1.1459, val_acc=0.7120
Epoch 119: train_loss=0.6012, val_loss=1.1424, val_acc=0.7140
Epoch 120: train_loss=0.5895, val_loss=1.1408, val_acc=0.7140
Epoch 121: train_loss=0.5757, val_loss=1.1373, val_acc=0.7160
Epoch 122: train_loss=0.5857, val_loss=1.1336, val_acc=0.7100
Epoch 123: train_loss=0.5523, val_loss=1.1301, val_acc=0.7120
Epoch 124: train_loss=0.5674, val_loss=1.1274, val_acc=0.7160
Epoch 125: train_loss=0.6118, val_loss=1.1262, val_acc=0.7160
Epoch 126: train_loss=0.5479, val_loss=1.1273, val_acc=0.7120
Epoch 127: train_loss=0.5627, val_loss=1.1290, val_acc=0.7080
Epoch 128: train_loss=0.5886, val_loss=1.1321, val_acc=0.7060
Epoch 129: train_loss=0.5415, val_loss=1.1340, val_acc=0.7000
Epoch 130: train_loss=0.5517, val_loss=1.1331, val_acc=0.7040
Epoch 131: train_loss=0.5717, val_loss=1.1300, val_acc=0.7020
Epoch 132: train_loss=0.5814, val_loss=1.1250, val_acc=0.7020
Epoch 133: train_loss=0.5391, val_loss=1.1176, val_acc=0.7080
Epoch 134: train_loss=0.5389, val_loss=1.1098, val_acc=0.7160
Epoch 135: train_loss=0.5045, val_loss=1.1048, val_acc=0.7240
Epoch 136: train_loss=0.5138, val_loss=1.1017, val_acc=0.7160
Epoch 137: train_loss=0.5132, val_loss=1.1019, val_acc=0.7120
Epoch 138: train_loss=0.5193, val_loss=1.1034, val_acc=0.7080
Epoch 139: train_loss=0.5620, val_loss=1.1042, val_acc=0.7140
Epoch 140: train_loss=0.5274, val_loss=1.1043, val_acc=0.7160
Epoch 141: train_loss=0.5297, val_loss=1.1032, val_acc=0.7120
Epoch 142: train_loss=0.5850, val_loss=1.1034, val_acc=0.7100
Epoch 143: train_loss=0.5118, val_loss=1.1035, val_acc=0.7080
Epoch 144: train_loss=0.5142, val_loss=1.1023, val_acc=0.7100
Epoch 145: train_loss=0.4749, val_loss=1.1012, val_acc=0.7080
Epoch 146: train_loss=0.5254, val_loss=1.0974, val_acc=0.7080
Epoch 147: train_loss=0.4949, val_loss=1.0948, val_acc=0.7140
Epoch 148: train_loss=0.5189, val_loss=1.0918, val_acc=0.7140
Epoch 149: train_loss=0.4922, val_loss=1.0894, val_acc=0.7140
Epoch 150: train_loss=0.5093, val_loss=1.0869, val_acc=0.7200
Epoch 151: train_loss=0.5052, val_loss=1.0856, val_acc=0.7220
Epoch 152: train_loss=0.4788, val_loss=1.0843, val_acc=0.7140
Epoch 153: train_loss=0.4834, val_loss=1.0840, val_acc=0.7020
Epoch 154: train_loss=0.4966, val_loss=1.0835, val_acc=0.7040
Epoch 155: train_loss=0.5002, val_loss=1.0808, val_acc=0.7020
Epoch 156: train_loss=0.5343, val_loss=1.0774, val_acc=0.7140
Epoch 157: train_loss=0.4764, val_loss=1.0745, val_acc=0.7180
Epoch 158: train_loss=0.4499, val_loss=1.0742, val_acc=0.7140
Epoch 159: train_loss=0.4674, val_loss=1.0738, val_acc=0.7100
Epoch 160: train_loss=0.4780, val_loss=1.0743, val_acc=0.7140
Epoch 161: train_loss=0.4771, val_loss=1.0758, val_acc=0.7160
Epoch 162: train_loss=0.4760, val_loss=1.0753, val_acc=0.7100
Epoch 163: train_loss=0.4783, val_loss=1.0738, val_acc=0.7120
Epoch 164: train_loss=0.4840, val_loss=1.0704, val_acc=0.7140
Epoch 165: train_loss=0.4616, val_loss=1.0679, val_acc=0.7120
Epoch 166: train_loss=0.4848, val_loss=1.0633, val_acc=0.7180
Epoch 167: train_loss=0.4845, val_loss=1.0607, val_acc=0.7180
Epoch 168: train_loss=0.4628, val_loss=1.0585, val_acc=0.7220
Epoch 169: train_loss=0.4542, val_loss=1.0570, val_acc=0.7260
Epoch 170: train_loss=0.4682, val_loss=1.0562, val_acc=0.7260
Epoch 171: train_loss=0.4287, val_loss=1.0567, val_acc=0.7220
Epoch 172: train_loss=0.4372, val_loss=1.0595, val_acc=0.7200
Epoch 173: train_loss=0.4986, val_loss=1.0617, val_acc=0.7140
Epoch 174: train_loss=0.4523, val_loss=1.0628, val_acc=0.7140
Epoch 175: train_loss=0.4538, val_loss=1.0603, val_acc=0.7160
Epoch 176: train_loss=0.4610, val_loss=1.0562, val_acc=0.7240
Epoch 177: train_loss=0.4439, val_loss=1.0520, val_acc=0.7240
Epoch 178: train_loss=0.4506, val_loss=1.0481, val_acc=0.7160
Epoch 179: train_loss=0.4743, val_loss=1.0431, val_acc=0.7180
Epoch 180: train_loss=0.4314, val_loss=1.0421, val_acc=0.7220
Epoch 181: train_loss=0.4298, val_loss=1.0438, val_acc=0.7220
Epoch 182: train_loss=0.4425, val_loss=1.0483, val_acc=0.7200
Epoch 183: train_loss=0.4426, val_loss=1.0518, val_acc=0.7140
Epoch 184: train_loss=0.4403, val_loss=1.0553, val_acc=0.7080
Epoch 185: train_loss=0.4613, val_loss=1.0569, val_acc=0.7120
Epoch 186: train_loss=0.4309, val_loss=1.0577, val_acc=0.7120
Epoch 187: train_loss=0.4423, val_loss=1.0547, val_acc=0.7140
Epoch 188: train_loss=0.4383, val_loss=1.0504, val_acc=0.7140
Epoch 189: train_loss=0.4359, val_loss=1.0437, val_acc=0.7280
Epoch 190: train_loss=0.4039, val_loss=1.0386, val_acc=0.7260
Epoch 191: train_loss=0.4309, val_loss=1.0358, val_acc=0.7260
Epoch 192: train_loss=0.4384, val_loss=1.0352, val_acc=0.7180
Epoch 193: train_loss=0.4420, val_loss=1.0353, val_acc=0.7160
Epoch 194: train_loss=0.4261, val_loss=1.0363, val_acc=0.7140
Epoch 195: train_loss=0.4084, val_loss=1.0381, val_acc=0.7140
Epoch 196: train_loss=0.3925, val_loss=1.0370, val_acc=0.7180
Epoch 197: train_loss=0.4577, val_loss=1.0375, val_acc=0.7180
Epoch 198: train_loss=0.3870, val_loss=1.0379, val_acc=0.7180
Epoch 199: train_loss=0.3989, val_loss=1.0383, val_acc=0.7200
Epoch 200: train_loss=0.3837, val_loss=1.0383, val_acc=0.7200

Final test accuracy: 0.7200
