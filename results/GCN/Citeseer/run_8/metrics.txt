Epoch 1: train_loss=1.7921, val_loss=1.7920, val_acc=0.0660
Epoch 2: train_loss=1.7872, val_loss=1.7906, val_acc=0.1940
Epoch 3: train_loss=1.7821, val_loss=1.7896, val_acc=0.1620
Epoch 4: train_loss=1.7765, val_loss=1.7891, val_acc=0.1240
Epoch 5: train_loss=1.7709, val_loss=1.7893, val_acc=0.0800
Epoch 6: train_loss=1.7649, val_loss=1.7899, val_acc=0.0660
Epoch 7: train_loss=1.7553, val_loss=1.7895, val_acc=0.0660
Epoch 8: train_loss=1.7504, val_loss=1.7889, val_acc=0.0680
Epoch 9: train_loss=1.7479, val_loss=1.7877, val_acc=0.0680
Epoch 10: train_loss=1.7346, val_loss=1.7858, val_acc=0.0760
Epoch 11: train_loss=1.7294, val_loss=1.7830, val_acc=0.0960
Epoch 12: train_loss=1.7236, val_loss=1.7789, val_acc=0.1480
Epoch 13: train_loss=1.7196, val_loss=1.7745, val_acc=0.2140
Epoch 14: train_loss=1.7117, val_loss=1.7706, val_acc=0.2400
Epoch 15: train_loss=1.7021, val_loss=1.7668, val_acc=0.2620
Epoch 16: train_loss=1.6966, val_loss=1.7630, val_acc=0.2680
Epoch 17: train_loss=1.6854, val_loss=1.7591, val_acc=0.2760
Epoch 18: train_loss=1.6661, val_loss=1.7556, val_acc=0.2980
Epoch 19: train_loss=1.6656, val_loss=1.7522, val_acc=0.3120
Epoch 20: train_loss=1.6431, val_loss=1.7492, val_acc=0.3260
Epoch 21: train_loss=1.6342, val_loss=1.7457, val_acc=0.3340
Epoch 22: train_loss=1.6229, val_loss=1.7423, val_acc=0.3340
Epoch 23: train_loss=1.6251, val_loss=1.7387, val_acc=0.3280
Epoch 24: train_loss=1.6134, val_loss=1.7348, val_acc=0.3300
Epoch 25: train_loss=1.5985, val_loss=1.7306, val_acc=0.3480
Epoch 26: train_loss=1.5838, val_loss=1.7259, val_acc=0.3600
Epoch 27: train_loss=1.5778, val_loss=1.7205, val_acc=0.3800
Epoch 28: train_loss=1.5868, val_loss=1.7148, val_acc=0.4060
Epoch 29: train_loss=1.5502, val_loss=1.7084, val_acc=0.4200
Epoch 30: train_loss=1.5507, val_loss=1.7018, val_acc=0.4700
Epoch 31: train_loss=1.5325, val_loss=1.6948, val_acc=0.5060
Epoch 32: train_loss=1.5323, val_loss=1.6876, val_acc=0.5280
Epoch 33: train_loss=1.5103, val_loss=1.6816, val_acc=0.5360
Epoch 34: train_loss=1.4879, val_loss=1.6757, val_acc=0.5440
Epoch 35: train_loss=1.4701, val_loss=1.6699, val_acc=0.5580
Epoch 36: train_loss=1.4535, val_loss=1.6640, val_acc=0.5660
Epoch 37: train_loss=1.4326, val_loss=1.6581, val_acc=0.5680
Epoch 38: train_loss=1.4384, val_loss=1.6521, val_acc=0.5700
Epoch 39: train_loss=1.4301, val_loss=1.6467, val_acc=0.5780
Epoch 40: train_loss=1.3926, val_loss=1.6415, val_acc=0.5880
Epoch 41: train_loss=1.4018, val_loss=1.6367, val_acc=0.5900
Epoch 42: train_loss=1.3611, val_loss=1.6309, val_acc=0.5960
Epoch 43: train_loss=1.4017, val_loss=1.6248, val_acc=0.6040
Epoch 44: train_loss=1.3784, val_loss=1.6186, val_acc=0.6020
Epoch 45: train_loss=1.3473, val_loss=1.6117, val_acc=0.6160
Epoch 46: train_loss=1.3570, val_loss=1.6049, val_acc=0.6200
Epoch 47: train_loss=1.3480, val_loss=1.5980, val_acc=0.6220
Epoch 48: train_loss=1.3243, val_loss=1.5907, val_acc=0.6180
Epoch 49: train_loss=1.2947, val_loss=1.5837, val_acc=0.6180
Epoch 50: train_loss=1.2655, val_loss=1.5773, val_acc=0.6140
Epoch 51: train_loss=1.2675, val_loss=1.5709, val_acc=0.6160
Epoch 52: train_loss=1.2653, val_loss=1.5642, val_acc=0.6120
Epoch 53: train_loss=1.2405, val_loss=1.5577, val_acc=0.6120
Epoch 54: train_loss=1.1868, val_loss=1.5501, val_acc=0.6220
Epoch 55: train_loss=1.2114, val_loss=1.5421, val_acc=0.6300
Epoch 56: train_loss=1.2463, val_loss=1.5353, val_acc=0.6280
Epoch 57: train_loss=1.1768, val_loss=1.5276, val_acc=0.6380
Epoch 58: train_loss=1.1638, val_loss=1.5202, val_acc=0.6420
Epoch 59: train_loss=1.1615, val_loss=1.5122, val_acc=0.6440
Epoch 60: train_loss=1.1399, val_loss=1.5049, val_acc=0.6500
Epoch 61: train_loss=1.1314, val_loss=1.4988, val_acc=0.6500
Epoch 62: train_loss=1.1191, val_loss=1.4937, val_acc=0.6460
Epoch 63: train_loss=1.1040, val_loss=1.4882, val_acc=0.6420
Epoch 64: train_loss=1.0883, val_loss=1.4830, val_acc=0.6400
Epoch 65: train_loss=1.0743, val_loss=1.4781, val_acc=0.6380
Epoch 66: train_loss=1.0614, val_loss=1.4727, val_acc=0.6480
Epoch 67: train_loss=1.0610, val_loss=1.4668, val_acc=0.6540
Epoch 68: train_loss=1.0401, val_loss=1.4587, val_acc=0.6620
Epoch 69: train_loss=1.0329, val_loss=1.4507, val_acc=0.6620
Epoch 70: train_loss=1.0303, val_loss=1.4435, val_acc=0.6620
Epoch 71: train_loss=1.0115, val_loss=1.4365, val_acc=0.6640
Epoch 72: train_loss=1.0011, val_loss=1.4295, val_acc=0.6680
Epoch 73: train_loss=0.9796, val_loss=1.4211, val_acc=0.6700
Epoch 74: train_loss=0.9668, val_loss=1.4141, val_acc=0.6700
Epoch 75: train_loss=0.9471, val_loss=1.4089, val_acc=0.6700
Epoch 76: train_loss=0.9510, val_loss=1.4040, val_acc=0.6700
Epoch 77: train_loss=0.9410, val_loss=1.3990, val_acc=0.6680
Epoch 78: train_loss=0.9306, val_loss=1.3949, val_acc=0.6620
Epoch 79: train_loss=0.9560, val_loss=1.3899, val_acc=0.6600
Epoch 80: train_loss=0.8805, val_loss=1.3850, val_acc=0.6660
Epoch 81: train_loss=0.8959, val_loss=1.3790, val_acc=0.6700
Epoch 82: train_loss=0.8993, val_loss=1.3726, val_acc=0.6680
Epoch 83: train_loss=0.9083, val_loss=1.3659, val_acc=0.6720
Epoch 84: train_loss=0.8452, val_loss=1.3591, val_acc=0.6760
Epoch 85: train_loss=0.9064, val_loss=1.3535, val_acc=0.6740
Epoch 86: train_loss=0.8770, val_loss=1.3488, val_acc=0.6720
Epoch 87: train_loss=0.8974, val_loss=1.3428, val_acc=0.6740
Epoch 88: train_loss=0.8553, val_loss=1.3367, val_acc=0.6760
Epoch 89: train_loss=0.8510, val_loss=1.3310, val_acc=0.6780
Epoch 90: train_loss=0.8097, val_loss=1.3248, val_acc=0.6780
Epoch 91: train_loss=0.8656, val_loss=1.3194, val_acc=0.6760
Epoch 92: train_loss=0.8265, val_loss=1.3153, val_acc=0.6740
Epoch 93: train_loss=0.8576, val_loss=1.3124, val_acc=0.6760
Epoch 94: train_loss=0.8475, val_loss=1.3079, val_acc=0.6820
Epoch 95: train_loss=0.8294, val_loss=1.3043, val_acc=0.6900
Epoch 96: train_loss=0.7864, val_loss=1.3008, val_acc=0.6940
Epoch 97: train_loss=0.7973, val_loss=1.2978, val_acc=0.6900
Epoch 98: train_loss=0.8199, val_loss=1.2951, val_acc=0.6840
Epoch 99: train_loss=0.7909, val_loss=1.2917, val_acc=0.6780
Epoch 100: train_loss=0.8150, val_loss=1.2879, val_acc=0.6820
Epoch 101: train_loss=0.8252, val_loss=1.2830, val_acc=0.6820
Epoch 102: train_loss=0.7549, val_loss=1.2779, val_acc=0.6800
Epoch 103: train_loss=0.7667, val_loss=1.2725, val_acc=0.6860
Epoch 104: train_loss=0.7775, val_loss=1.2668, val_acc=0.6880
Epoch 105: train_loss=0.7724, val_loss=1.2623, val_acc=0.6840
Epoch 106: train_loss=0.7433, val_loss=1.2597, val_acc=0.6860
Epoch 107: train_loss=0.7211, val_loss=1.2562, val_acc=0.6880
Epoch 108: train_loss=0.7773, val_loss=1.2556, val_acc=0.6860
Epoch 109: train_loss=0.7075, val_loss=1.2551, val_acc=0.6900
Epoch 110: train_loss=0.7369, val_loss=1.2540, val_acc=0.6860
Epoch 111: train_loss=0.6788, val_loss=1.2521, val_acc=0.6840
Epoch 112: train_loss=0.7345, val_loss=1.2489, val_acc=0.6860
Epoch 113: train_loss=0.6954, val_loss=1.2444, val_acc=0.6840
Epoch 114: train_loss=0.6516, val_loss=1.2405, val_acc=0.6880
Epoch 115: train_loss=0.6757, val_loss=1.2360, val_acc=0.6860
Epoch 116: train_loss=0.7066, val_loss=1.2321, val_acc=0.6900
Epoch 117: train_loss=0.7069, val_loss=1.2296, val_acc=0.6860
Epoch 118: train_loss=0.7238, val_loss=1.2284, val_acc=0.6900
Epoch 119: train_loss=0.6518, val_loss=1.2273, val_acc=0.7000
Epoch 120: train_loss=0.7024, val_loss=1.2254, val_acc=0.6960
Epoch 121: train_loss=0.6744, val_loss=1.2243, val_acc=0.6980
Epoch 122: train_loss=0.6694, val_loss=1.2215, val_acc=0.6960
Epoch 123: train_loss=0.6870, val_loss=1.2181, val_acc=0.6880
Epoch 124: train_loss=0.6956, val_loss=1.2128, val_acc=0.6920
Epoch 125: train_loss=0.6174, val_loss=1.2079, val_acc=0.6920
Epoch 126: train_loss=0.6485, val_loss=1.2037, val_acc=0.6920
Epoch 127: train_loss=0.6189, val_loss=1.2011, val_acc=0.6940
Epoch 128: train_loss=0.6275, val_loss=1.2008, val_acc=0.6920
Epoch 129: train_loss=0.6399, val_loss=1.1989, val_acc=0.6920
Epoch 130: train_loss=0.6757, val_loss=1.1953, val_acc=0.6840
Epoch 131: train_loss=0.6265, val_loss=1.1912, val_acc=0.6900
Epoch 132: train_loss=0.6778, val_loss=1.1877, val_acc=0.6900
Epoch 133: train_loss=0.6441, val_loss=1.1871, val_acc=0.6900
Epoch 134: train_loss=0.6392, val_loss=1.1863, val_acc=0.6920
Epoch 135: train_loss=0.6236, val_loss=1.1875, val_acc=0.6960
Epoch 136: train_loss=0.5886, val_loss=1.1888, val_acc=0.6900
Epoch 137: train_loss=0.5861, val_loss=1.1873, val_acc=0.7000
Epoch 138: train_loss=0.6624, val_loss=1.1861, val_acc=0.6960
Epoch 139: train_loss=0.5867, val_loss=1.1842, val_acc=0.6920
Epoch 140: train_loss=0.5744, val_loss=1.1801, val_acc=0.6960
Epoch 141: train_loss=0.6043, val_loss=1.1750, val_acc=0.6960
Epoch 142: train_loss=0.6007, val_loss=1.1708, val_acc=0.6960
Epoch 143: train_loss=0.5696, val_loss=1.1665, val_acc=0.7000
Epoch 144: train_loss=0.6114, val_loss=1.1633, val_acc=0.6960
Epoch 145: train_loss=0.6398, val_loss=1.1623, val_acc=0.6960
Epoch 146: train_loss=0.6043, val_loss=1.1626, val_acc=0.6940
Epoch 147: train_loss=0.6197, val_loss=1.1626, val_acc=0.6880
Epoch 148: train_loss=0.5709, val_loss=1.1619, val_acc=0.6900
Epoch 149: train_loss=0.6059, val_loss=1.1605, val_acc=0.6980
Epoch 150: train_loss=0.5863, val_loss=1.1587, val_acc=0.6960
Epoch 151: train_loss=0.5640, val_loss=1.1557, val_acc=0.6980
Epoch 152: train_loss=0.5847, val_loss=1.1537, val_acc=0.6980
Epoch 153: train_loss=0.5894, val_loss=1.1529, val_acc=0.7020
Epoch 154: train_loss=0.5658, val_loss=1.1500, val_acc=0.7020
Epoch 155: train_loss=0.5936, val_loss=1.1473, val_acc=0.7000
Epoch 156: train_loss=0.5884, val_loss=1.1451, val_acc=0.6980
Epoch 157: train_loss=0.5412, val_loss=1.1415, val_acc=0.6960
Epoch 158: train_loss=0.5466, val_loss=1.1402, val_acc=0.7000
Epoch 159: train_loss=0.5883, val_loss=1.1399, val_acc=0.7040
Epoch 160: train_loss=0.5712, val_loss=1.1389, val_acc=0.7000
Epoch 161: train_loss=0.5606, val_loss=1.1370, val_acc=0.7000
Epoch 162: train_loss=0.5414, val_loss=1.1331, val_acc=0.7000
Epoch 163: train_loss=0.5540, val_loss=1.1302, val_acc=0.6980
Epoch 164: train_loss=0.5482, val_loss=1.1291, val_acc=0.7000
Epoch 165: train_loss=0.5383, val_loss=1.1301, val_acc=0.6980
Epoch 166: train_loss=0.5326, val_loss=1.1305, val_acc=0.6960
Epoch 167: train_loss=0.4974, val_loss=1.1313, val_acc=0.6960
Epoch 168: train_loss=0.5538, val_loss=1.1288, val_acc=0.6980
Epoch 169: train_loss=0.5344, val_loss=1.1237, val_acc=0.7000
Epoch 170: train_loss=0.5477, val_loss=1.1191, val_acc=0.6980
Epoch 171: train_loss=0.5666, val_loss=1.1166, val_acc=0.7040
Epoch 172: train_loss=0.5902, val_loss=1.1146, val_acc=0.7100
Epoch 173: train_loss=0.4790, val_loss=1.1138, val_acc=0.7060
Epoch 174: train_loss=0.5501, val_loss=1.1154, val_acc=0.7040
Epoch 175: train_loss=0.4761, val_loss=1.1176, val_acc=0.7020
Epoch 176: train_loss=0.5015, val_loss=1.1204, val_acc=0.7020
Epoch 177: train_loss=0.5037, val_loss=1.1221, val_acc=0.7000
Epoch 178: train_loss=0.4937, val_loss=1.1220, val_acc=0.6980
Epoch 179: train_loss=0.5493, val_loss=1.1199, val_acc=0.6960
Epoch 180: train_loss=0.5248, val_loss=1.1163, val_acc=0.7000
Epoch 181: train_loss=0.5057, val_loss=1.1117, val_acc=0.7020
Epoch 182: train_loss=0.5070, val_loss=1.1079, val_acc=0.7020
Epoch 183: train_loss=0.5666, val_loss=1.1043, val_acc=0.7020
Epoch 184: train_loss=0.4898, val_loss=1.1025, val_acc=0.7000
Epoch 185: train_loss=0.5628, val_loss=1.0995, val_acc=0.7060
Epoch 186: train_loss=0.5499, val_loss=1.0974, val_acc=0.7060
Epoch 187: train_loss=0.5343, val_loss=1.0987, val_acc=0.7040
Epoch 188: train_loss=0.4742, val_loss=1.1008, val_acc=0.7040
Epoch 189: train_loss=0.4978, val_loss=1.1030, val_acc=0.7020
Epoch 190: train_loss=0.5387, val_loss=1.1053, val_acc=0.6980
Epoch 191: train_loss=0.5601, val_loss=1.1034, val_acc=0.6940
Epoch 192: train_loss=0.4901, val_loss=1.0996, val_acc=0.6960
Epoch 193: train_loss=0.4261, val_loss=1.0952, val_acc=0.7000
Epoch 194: train_loss=0.4733, val_loss=1.0930, val_acc=0.7000
Epoch 195: train_loss=0.5062, val_loss=1.0914, val_acc=0.7020
Epoch 196: train_loss=0.4628, val_loss=1.0918, val_acc=0.7040
Epoch 197: train_loss=0.5022, val_loss=1.0917, val_acc=0.7080
Epoch 198: train_loss=0.4508, val_loss=1.0908, val_acc=0.7060
Epoch 199: train_loss=0.4787, val_loss=1.0900, val_acc=0.7040
Epoch 200: train_loss=0.4875, val_loss=1.0887, val_acc=0.7060

Final test accuracy: 0.7080
