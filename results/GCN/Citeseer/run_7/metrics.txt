Epoch 1: train_loss=1.7924, val_loss=1.7914, val_acc=0.2180
Epoch 2: train_loss=1.7888, val_loss=1.7909, val_acc=0.2060
Epoch 3: train_loss=1.7849, val_loss=1.7919, val_acc=0.0800
Epoch 4: train_loss=1.7816, val_loss=1.7918, val_acc=0.0620
Epoch 5: train_loss=1.7768, val_loss=1.7906, val_acc=0.0620
Epoch 6: train_loss=1.7711, val_loss=1.7886, val_acc=0.0880
Epoch 7: train_loss=1.7614, val_loss=1.7867, val_acc=0.0980
Epoch 8: train_loss=1.7581, val_loss=1.7843, val_acc=0.1080
Epoch 9: train_loss=1.7504, val_loss=1.7815, val_acc=0.1120
Epoch 10: train_loss=1.7450, val_loss=1.7786, val_acc=0.1120
Epoch 11: train_loss=1.7355, val_loss=1.7756, val_acc=0.1200
Epoch 12: train_loss=1.7367, val_loss=1.7717, val_acc=0.1420
Epoch 13: train_loss=1.7238, val_loss=1.7681, val_acc=0.1580
Epoch 14: train_loss=1.7119, val_loss=1.7646, val_acc=0.1820
Epoch 15: train_loss=1.7068, val_loss=1.7610, val_acc=0.2260
Epoch 16: train_loss=1.6993, val_loss=1.7576, val_acc=0.2520
Epoch 17: train_loss=1.6895, val_loss=1.7536, val_acc=0.3120
Epoch 18: train_loss=1.6767, val_loss=1.7495, val_acc=0.3460
Epoch 19: train_loss=1.6705, val_loss=1.7450, val_acc=0.3860
Epoch 20: train_loss=1.6560, val_loss=1.7403, val_acc=0.4060
Epoch 21: train_loss=1.6411, val_loss=1.7355, val_acc=0.4340
Epoch 22: train_loss=1.6341, val_loss=1.7307, val_acc=0.4640
Epoch 23: train_loss=1.6296, val_loss=1.7254, val_acc=0.4860
Epoch 24: train_loss=1.6234, val_loss=1.7196, val_acc=0.5120
Epoch 25: train_loss=1.5992, val_loss=1.7135, val_acc=0.5360
Epoch 26: train_loss=1.6030, val_loss=1.7073, val_acc=0.5620
Epoch 27: train_loss=1.5867, val_loss=1.7002, val_acc=0.5900
Epoch 28: train_loss=1.5664, val_loss=1.6931, val_acc=0.6160
Epoch 29: train_loss=1.5805, val_loss=1.6868, val_acc=0.6280
Epoch 30: train_loss=1.5490, val_loss=1.6810, val_acc=0.6360
Epoch 31: train_loss=1.5204, val_loss=1.6756, val_acc=0.6360
Epoch 32: train_loss=1.5119, val_loss=1.6704, val_acc=0.6360
Epoch 33: train_loss=1.4996, val_loss=1.6656, val_acc=0.6240
Epoch 34: train_loss=1.4974, val_loss=1.6602, val_acc=0.6140
Epoch 35: train_loss=1.4751, val_loss=1.6538, val_acc=0.6140
Epoch 36: train_loss=1.4615, val_loss=1.6475, val_acc=0.6140
Epoch 37: train_loss=1.4478, val_loss=1.6408, val_acc=0.6240
Epoch 38: train_loss=1.4328, val_loss=1.6337, val_acc=0.6320
Epoch 39: train_loss=1.4353, val_loss=1.6261, val_acc=0.6560
Epoch 40: train_loss=1.4249, val_loss=1.6181, val_acc=0.6680
Epoch 41: train_loss=1.3979, val_loss=1.6104, val_acc=0.6700
Epoch 42: train_loss=1.3883, val_loss=1.6035, val_acc=0.6800
Epoch 43: train_loss=1.3585, val_loss=1.5965, val_acc=0.6800
Epoch 44: train_loss=1.3540, val_loss=1.5901, val_acc=0.6820
Epoch 45: train_loss=1.3394, val_loss=1.5836, val_acc=0.6820
Epoch 46: train_loss=1.3581, val_loss=1.5765, val_acc=0.6800
Epoch 47: train_loss=1.3077, val_loss=1.5693, val_acc=0.6800
Epoch 48: train_loss=1.2825, val_loss=1.5620, val_acc=0.6740
Epoch 49: train_loss=1.3126, val_loss=1.5543, val_acc=0.6720
Epoch 50: train_loss=1.2713, val_loss=1.5460, val_acc=0.6720
Epoch 51: train_loss=1.2198, val_loss=1.5383, val_acc=0.6740
Epoch 52: train_loss=1.2707, val_loss=1.5303, val_acc=0.6780
Epoch 53: train_loss=1.2562, val_loss=1.5221, val_acc=0.6840
Epoch 54: train_loss=1.2505, val_loss=1.5148, val_acc=0.6860
Epoch 55: train_loss=1.2116, val_loss=1.5075, val_acc=0.6940
Epoch 56: train_loss=1.2036, val_loss=1.5000, val_acc=0.6900
Epoch 57: train_loss=1.1685, val_loss=1.4926, val_acc=0.6940
Epoch 58: train_loss=1.1450, val_loss=1.4855, val_acc=0.6900
Epoch 59: train_loss=1.1457, val_loss=1.4784, val_acc=0.6880
Epoch 60: train_loss=1.0881, val_loss=1.4719, val_acc=0.6920
Epoch 61: train_loss=1.1555, val_loss=1.4661, val_acc=0.6900
Epoch 62: train_loss=1.1096, val_loss=1.4609, val_acc=0.6880
Epoch 63: train_loss=1.0857, val_loss=1.4559, val_acc=0.6780
Epoch 64: train_loss=1.1055, val_loss=1.4508, val_acc=0.6740
Epoch 65: train_loss=1.0841, val_loss=1.4448, val_acc=0.6820
Epoch 66: train_loss=1.0644, val_loss=1.4379, val_acc=0.6880
Epoch 67: train_loss=1.0728, val_loss=1.4309, val_acc=0.6920
Epoch 68: train_loss=1.0246, val_loss=1.4227, val_acc=0.7020
Epoch 69: train_loss=0.9960, val_loss=1.4146, val_acc=0.7160
Epoch 70: train_loss=1.0743, val_loss=1.4070, val_acc=0.7180
Epoch 71: train_loss=1.0031, val_loss=1.4003, val_acc=0.7200
Epoch 72: train_loss=0.9840, val_loss=1.3933, val_acc=0.7220
Epoch 73: train_loss=1.0003, val_loss=1.3868, val_acc=0.7240
Epoch 74: train_loss=0.9872, val_loss=1.3803, val_acc=0.7220
Epoch 75: train_loss=0.9925, val_loss=1.3742, val_acc=0.7220
Epoch 76: train_loss=0.9824, val_loss=1.3697, val_acc=0.7180
Epoch 77: train_loss=0.9753, val_loss=1.3657, val_acc=0.7140
Epoch 78: train_loss=0.9563, val_loss=1.3619, val_acc=0.7100
Epoch 79: train_loss=0.9247, val_loss=1.3585, val_acc=0.6980
Epoch 80: train_loss=0.9083, val_loss=1.3546, val_acc=0.7040
Epoch 81: train_loss=0.9129, val_loss=1.3501, val_acc=0.7000
Epoch 82: train_loss=0.8869, val_loss=1.3452, val_acc=0.7020
Epoch 83: train_loss=0.8836, val_loss=1.3393, val_acc=0.7020
Epoch 84: train_loss=0.8810, val_loss=1.3327, val_acc=0.7080
Epoch 85: train_loss=0.8494, val_loss=1.3254, val_acc=0.7100
Epoch 86: train_loss=0.8754, val_loss=1.3199, val_acc=0.7180
Epoch 87: train_loss=0.8810, val_loss=1.3146, val_acc=0.7140
Epoch 88: train_loss=0.8652, val_loss=1.3096, val_acc=0.7080
Epoch 89: train_loss=0.8898, val_loss=1.3042, val_acc=0.7120
Epoch 90: train_loss=0.8660, val_loss=1.2998, val_acc=0.7140
Epoch 91: train_loss=0.9143, val_loss=1.2959, val_acc=0.7140
Epoch 92: train_loss=0.8671, val_loss=1.2919, val_acc=0.7140
Epoch 93: train_loss=0.7999, val_loss=1.2868, val_acc=0.7140
Epoch 94: train_loss=0.8000, val_loss=1.2823, val_acc=0.7160
Epoch 95: train_loss=0.8124, val_loss=1.2777, val_acc=0.7140
Epoch 96: train_loss=0.8069, val_loss=1.2732, val_acc=0.7160
Epoch 97: train_loss=0.7999, val_loss=1.2692, val_acc=0.7120
Epoch 98: train_loss=0.7718, val_loss=1.2649, val_acc=0.7100
Epoch 99: train_loss=0.7761, val_loss=1.2591, val_acc=0.7120
Epoch 100: train_loss=0.8019, val_loss=1.2530, val_acc=0.7140
Epoch 101: train_loss=0.7019, val_loss=1.2491, val_acc=0.7180
Epoch 102: train_loss=0.7831, val_loss=1.2456, val_acc=0.7180
Epoch 103: train_loss=0.7422, val_loss=1.2439, val_acc=0.7200
Epoch 104: train_loss=0.7508, val_loss=1.2419, val_acc=0.7120
Epoch 105: train_loss=0.7500, val_loss=1.2393, val_acc=0.7100
Epoch 106: train_loss=0.7069, val_loss=1.2372, val_acc=0.7080
Epoch 107: train_loss=0.7288, val_loss=1.2338, val_acc=0.7080
Epoch 108: train_loss=0.7482, val_loss=1.2306, val_acc=0.7080
Epoch 109: train_loss=0.7242, val_loss=1.2272, val_acc=0.7160
Epoch 110: train_loss=0.7279, val_loss=1.2216, val_acc=0.7160
Epoch 111: train_loss=0.7005, val_loss=1.2168, val_acc=0.7180
Epoch 112: train_loss=0.7153, val_loss=1.2137, val_acc=0.7160
Epoch 113: train_loss=0.7606, val_loss=1.2109, val_acc=0.7160
Epoch 114: train_loss=0.7073, val_loss=1.2089, val_acc=0.7160
Epoch 115: train_loss=0.6926, val_loss=1.2081, val_acc=0.7180
Epoch 116: train_loss=0.7078, val_loss=1.2068, val_acc=0.7200
Epoch 117: train_loss=0.7410, val_loss=1.2044, val_acc=0.7160
Epoch 118: train_loss=0.7157, val_loss=1.2013, val_acc=0.7120
Epoch 119: train_loss=0.7000, val_loss=1.1979, val_acc=0.7120
Epoch 120: train_loss=0.6871, val_loss=1.1933, val_acc=0.7160
Epoch 121: train_loss=0.6639, val_loss=1.1884, val_acc=0.7140
Epoch 122: train_loss=0.6995, val_loss=1.1835, val_acc=0.7160
Epoch 123: train_loss=0.6912, val_loss=1.1797, val_acc=0.7160
Epoch 124: train_loss=0.6770, val_loss=1.1771, val_acc=0.7180
Epoch 125: train_loss=0.6693, val_loss=1.1760, val_acc=0.7200
Epoch 126: train_loss=0.6541, val_loss=1.1775, val_acc=0.7140
Epoch 127: train_loss=0.6768, val_loss=1.1784, val_acc=0.7120
Epoch 128: train_loss=0.6367, val_loss=1.1769, val_acc=0.7120
Epoch 129: train_loss=0.6683, val_loss=1.1748, val_acc=0.7120
Epoch 130: train_loss=0.6427, val_loss=1.1718, val_acc=0.7160
Epoch 131: train_loss=0.6559, val_loss=1.1672, val_acc=0.7180
Epoch 132: train_loss=0.6020, val_loss=1.1629, val_acc=0.7120
Epoch 133: train_loss=0.6330, val_loss=1.1593, val_acc=0.7100
Epoch 134: train_loss=0.6536, val_loss=1.1577, val_acc=0.7100
Epoch 135: train_loss=0.6222, val_loss=1.1568, val_acc=0.7060
Epoch 136: train_loss=0.6436, val_loss=1.1583, val_acc=0.7100
Epoch 137: train_loss=0.6557, val_loss=1.1589, val_acc=0.7100
Epoch 138: train_loss=0.6472, val_loss=1.1570, val_acc=0.7120
Epoch 139: train_loss=0.6257, val_loss=1.1524, val_acc=0.7140
Epoch 140: train_loss=0.6152, val_loss=1.1477, val_acc=0.7160
Epoch 141: train_loss=0.5905, val_loss=1.1427, val_acc=0.7180
Epoch 142: train_loss=0.6096, val_loss=1.1378, val_acc=0.7180
Epoch 143: train_loss=0.5886, val_loss=1.1342, val_acc=0.7160
Epoch 144: train_loss=0.6183, val_loss=1.1325, val_acc=0.7060
Epoch 145: train_loss=0.6040, val_loss=1.1325, val_acc=0.7040
Epoch 146: train_loss=0.5789, val_loss=1.1341, val_acc=0.7060
Epoch 147: train_loss=0.6225, val_loss=1.1351, val_acc=0.7140
Epoch 148: train_loss=0.6200, val_loss=1.1345, val_acc=0.7120
Epoch 149: train_loss=0.5776, val_loss=1.1338, val_acc=0.7140
Epoch 150: train_loss=0.5769, val_loss=1.1308, val_acc=0.7160
Epoch 151: train_loss=0.5953, val_loss=1.1260, val_acc=0.7220
Epoch 152: train_loss=0.5804, val_loss=1.1197, val_acc=0.7200
Epoch 153: train_loss=0.5482, val_loss=1.1143, val_acc=0.7200
Epoch 154: train_loss=0.6188, val_loss=1.1102, val_acc=0.7160
Epoch 155: train_loss=0.5464, val_loss=1.1095, val_acc=0.7220
Epoch 156: train_loss=0.5673, val_loss=1.1115, val_acc=0.7180
Epoch 157: train_loss=0.6138, val_loss=1.1138, val_acc=0.7160
Epoch 158: train_loss=0.5929, val_loss=1.1148, val_acc=0.7180
Epoch 159: train_loss=0.5327, val_loss=1.1155, val_acc=0.7200
Epoch 160: train_loss=0.5763, val_loss=1.1140, val_acc=0.7200
Epoch 161: train_loss=0.5562, val_loss=1.1143, val_acc=0.7160
Epoch 162: train_loss=0.5541, val_loss=1.1133, val_acc=0.7040
Epoch 163: train_loss=0.5888, val_loss=1.1104, val_acc=0.7040
Epoch 164: train_loss=0.5534, val_loss=1.1076, val_acc=0.7060
Epoch 165: train_loss=0.5172, val_loss=1.1054, val_acc=0.7080
Epoch 166: train_loss=0.5581, val_loss=1.1033, val_acc=0.7080
Epoch 167: train_loss=0.5885, val_loss=1.1010, val_acc=0.7080
Epoch 168: train_loss=0.4801, val_loss=1.1004, val_acc=0.7020
Epoch 169: train_loss=0.5812, val_loss=1.0980, val_acc=0.7060
Epoch 170: train_loss=0.5192, val_loss=1.0973, val_acc=0.7100
Epoch 171: train_loss=0.5414, val_loss=1.0976, val_acc=0.7100
Epoch 172: train_loss=0.5365, val_loss=1.0974, val_acc=0.7080
Epoch 173: train_loss=0.5264, val_loss=1.0976, val_acc=0.7040
Epoch 174: train_loss=0.5588, val_loss=1.0974, val_acc=0.7080
Epoch 175: train_loss=0.5410, val_loss=1.0960, val_acc=0.7080
Epoch 176: train_loss=0.4819, val_loss=1.0942, val_acc=0.7100
Epoch 177: train_loss=0.5463, val_loss=1.0909, val_acc=0.7100
Epoch 178: train_loss=0.5022, val_loss=1.0883, val_acc=0.7060
Epoch 179: train_loss=0.5332, val_loss=1.0871, val_acc=0.7100
Epoch 180: train_loss=0.5115, val_loss=1.0857, val_acc=0.7100
Epoch 181: train_loss=0.5452, val_loss=1.0853, val_acc=0.7100
Epoch 182: train_loss=0.5174, val_loss=1.0849, val_acc=0.7120
Epoch 183: train_loss=0.5410, val_loss=1.0842, val_acc=0.7160
Epoch 184: train_loss=0.5342, val_loss=1.0833, val_acc=0.7100
Epoch 185: train_loss=0.5129, val_loss=1.0841, val_acc=0.7100
Epoch 186: train_loss=0.5179, val_loss=1.0846, val_acc=0.7080
Epoch 187: train_loss=0.5258, val_loss=1.0833, val_acc=0.7080
Epoch 188: train_loss=0.4737, val_loss=1.0816, val_acc=0.7100
Epoch 189: train_loss=0.5405, val_loss=1.0796, val_acc=0.7120
Epoch 190: train_loss=0.4945, val_loss=1.0783, val_acc=0.7120
Epoch 191: train_loss=0.4676, val_loss=1.0769, val_acc=0.7120
Epoch 192: train_loss=0.5159, val_loss=1.0749, val_acc=0.7120
Epoch 193: train_loss=0.5551, val_loss=1.0729, val_acc=0.7080
Epoch 194: train_loss=0.5286, val_loss=1.0694, val_acc=0.7100
Epoch 195: train_loss=0.4798, val_loss=1.0673, val_acc=0.7120
Epoch 196: train_loss=0.4935, val_loss=1.0656, val_acc=0.7180
Epoch 197: train_loss=0.4949, val_loss=1.0654, val_acc=0.7180
Epoch 198: train_loss=0.4920, val_loss=1.0638, val_acc=0.7160
Epoch 199: train_loss=0.5414, val_loss=1.0618, val_acc=0.7160
Epoch 200: train_loss=0.5099, val_loss=1.0603, val_acc=0.7160

Final test accuracy: 0.7070
