Epoch 1: train_loss=1.7920, val_loss=1.7913, val_acc=0.2280
Epoch 2: train_loss=1.7878, val_loss=1.7911, val_acc=0.2220
Epoch 3: train_loss=1.7834, val_loss=1.7895, val_acc=0.2240
Epoch 4: train_loss=1.7764, val_loss=1.7875, val_acc=0.2340
Epoch 5: train_loss=1.7671, val_loss=1.7856, val_acc=0.2480
Epoch 6: train_loss=1.7581, val_loss=1.7838, val_acc=0.3140
Epoch 7: train_loss=1.7482, val_loss=1.7819, val_acc=0.3200
Epoch 8: train_loss=1.7431, val_loss=1.7796, val_acc=0.3360
Epoch 9: train_loss=1.7323, val_loss=1.7763, val_acc=0.3880
Epoch 10: train_loss=1.7224, val_loss=1.7726, val_acc=0.4040
Epoch 11: train_loss=1.7052, val_loss=1.7686, val_acc=0.4040
Epoch 12: train_loss=1.6997, val_loss=1.7644, val_acc=0.4000
Epoch 13: train_loss=1.6869, val_loss=1.7600, val_acc=0.3960
Epoch 14: train_loss=1.6774, val_loss=1.7554, val_acc=0.4100
Epoch 15: train_loss=1.6697, val_loss=1.7508, val_acc=0.4160
Epoch 16: train_loss=1.6438, val_loss=1.7458, val_acc=0.4240
Epoch 17: train_loss=1.6294, val_loss=1.7405, val_acc=0.4420
Epoch 18: train_loss=1.6221, val_loss=1.7348, val_acc=0.4540
Epoch 19: train_loss=1.6067, val_loss=1.7290, val_acc=0.4740
Epoch 20: train_loss=1.6123, val_loss=1.7230, val_acc=0.4880
Epoch 21: train_loss=1.5839, val_loss=1.7168, val_acc=0.5040
Epoch 22: train_loss=1.5884, val_loss=1.7104, val_acc=0.5200
Epoch 23: train_loss=1.5655, val_loss=1.7038, val_acc=0.5360
Epoch 24: train_loss=1.5361, val_loss=1.6972, val_acc=0.5440
Epoch 25: train_loss=1.5342, val_loss=1.6904, val_acc=0.5500
Epoch 26: train_loss=1.5088, val_loss=1.6838, val_acc=0.5620
Epoch 27: train_loss=1.4992, val_loss=1.6775, val_acc=0.5660
Epoch 28: train_loss=1.4903, val_loss=1.6713, val_acc=0.5660
Epoch 29: train_loss=1.4777, val_loss=1.6653, val_acc=0.5700
Epoch 30: train_loss=1.4597, val_loss=1.6594, val_acc=0.5780
Epoch 31: train_loss=1.4302, val_loss=1.6533, val_acc=0.5740
Epoch 32: train_loss=1.4345, val_loss=1.6474, val_acc=0.5760
Epoch 33: train_loss=1.4053, val_loss=1.6412, val_acc=0.5720
Epoch 34: train_loss=1.3907, val_loss=1.6348, val_acc=0.5720
Epoch 35: train_loss=1.3956, val_loss=1.6283, val_acc=0.5720
Epoch 36: train_loss=1.3879, val_loss=1.6219, val_acc=0.5660
Epoch 37: train_loss=1.3559, val_loss=1.6144, val_acc=0.5800
Epoch 38: train_loss=1.3026, val_loss=1.6065, val_acc=0.5940
Epoch 39: train_loss=1.3182, val_loss=1.5974, val_acc=0.6040
Epoch 40: train_loss=1.3302, val_loss=1.5879, val_acc=0.6220
Epoch 41: train_loss=1.3054, val_loss=1.5781, val_acc=0.6320
Epoch 42: train_loss=1.2851, val_loss=1.5686, val_acc=0.6420
Epoch 43: train_loss=1.2483, val_loss=1.5598, val_acc=0.6560
Epoch 44: train_loss=1.2438, val_loss=1.5510, val_acc=0.6680
Epoch 45: train_loss=1.2274, val_loss=1.5432, val_acc=0.6740
Epoch 46: train_loss=1.2213, val_loss=1.5361, val_acc=0.6760
Epoch 47: train_loss=1.1967, val_loss=1.5290, val_acc=0.6740
Epoch 48: train_loss=1.1765, val_loss=1.5217, val_acc=0.6760
Epoch 49: train_loss=1.1558, val_loss=1.5147, val_acc=0.6740
Epoch 50: train_loss=1.1217, val_loss=1.5076, val_acc=0.6720
Epoch 51: train_loss=1.1351, val_loss=1.5005, val_acc=0.6740
Epoch 52: train_loss=1.1110, val_loss=1.4929, val_acc=0.6740
Epoch 53: train_loss=1.1020, val_loss=1.4844, val_acc=0.6740
Epoch 54: train_loss=1.0694, val_loss=1.4759, val_acc=0.6800
Epoch 55: train_loss=1.0520, val_loss=1.4675, val_acc=0.6800
Epoch 56: train_loss=1.0665, val_loss=1.4597, val_acc=0.6740
Epoch 57: train_loss=1.0583, val_loss=1.4520, val_acc=0.6800
Epoch 58: train_loss=1.0173, val_loss=1.4440, val_acc=0.6840
Epoch 59: train_loss=1.0234, val_loss=1.4357, val_acc=0.6900
Epoch 60: train_loss=1.0159, val_loss=1.4270, val_acc=0.6980
Epoch 61: train_loss=1.0076, val_loss=1.4175, val_acc=0.7080
Epoch 62: train_loss=0.9884, val_loss=1.4088, val_acc=0.7160
Epoch 63: train_loss=0.9849, val_loss=1.4003, val_acc=0.7180
Epoch 64: train_loss=0.9657, val_loss=1.3922, val_acc=0.7200
Epoch 65: train_loss=0.9470, val_loss=1.3851, val_acc=0.7220
Epoch 66: train_loss=0.9303, val_loss=1.3788, val_acc=0.7240
Epoch 67: train_loss=0.8966, val_loss=1.3736, val_acc=0.7200
Epoch 68: train_loss=0.9155, val_loss=1.3684, val_acc=0.7180
Epoch 69: train_loss=0.8901, val_loss=1.3631, val_acc=0.7180
Epoch 70: train_loss=0.8733, val_loss=1.3567, val_acc=0.7180
Epoch 71: train_loss=0.8428, val_loss=1.3501, val_acc=0.7140
Epoch 72: train_loss=0.8731, val_loss=1.3428, val_acc=0.7140
Epoch 73: train_loss=0.8812, val_loss=1.3351, val_acc=0.7140
Epoch 74: train_loss=0.8080, val_loss=1.3273, val_acc=0.7200
Epoch 75: train_loss=0.8377, val_loss=1.3202, val_acc=0.7200
Epoch 76: train_loss=0.8211, val_loss=1.3137, val_acc=0.7200
Epoch 77: train_loss=0.7990, val_loss=1.3084, val_acc=0.7180
Epoch 78: train_loss=0.8199, val_loss=1.3041, val_acc=0.7240
Epoch 79: train_loss=0.7973, val_loss=1.3004, val_acc=0.7200
Epoch 80: train_loss=0.7846, val_loss=1.2967, val_acc=0.7160
Epoch 81: train_loss=0.7913, val_loss=1.2923, val_acc=0.7120
Epoch 82: train_loss=0.7619, val_loss=1.2881, val_acc=0.7140
Epoch 83: train_loss=0.7706, val_loss=1.2827, val_acc=0.7100
Epoch 84: train_loss=0.7752, val_loss=1.2756, val_acc=0.7120
Epoch 85: train_loss=0.7728, val_loss=1.2685, val_acc=0.7140
Epoch 86: train_loss=0.7460, val_loss=1.2618, val_acc=0.7140
Epoch 87: train_loss=0.7120, val_loss=1.2568, val_acc=0.7180
Epoch 88: train_loss=0.7006, val_loss=1.2532, val_acc=0.7140
Epoch 89: train_loss=0.7039, val_loss=1.2493, val_acc=0.7160
Epoch 90: train_loss=0.7207, val_loss=1.2455, val_acc=0.7200
Epoch 91: train_loss=0.6822, val_loss=1.2416, val_acc=0.7180
Epoch 92: train_loss=0.7226, val_loss=1.2374, val_acc=0.7200
Epoch 93: train_loss=0.6887, val_loss=1.2333, val_acc=0.7160
Epoch 94: train_loss=0.6624, val_loss=1.2293, val_acc=0.7100
Epoch 95: train_loss=0.6882, val_loss=1.2243, val_acc=0.7140
Epoch 96: train_loss=0.7031, val_loss=1.2177, val_acc=0.7200
Epoch 97: train_loss=0.6707, val_loss=1.2115, val_acc=0.7240
Epoch 98: train_loss=0.6879, val_loss=1.2063, val_acc=0.7300
Epoch 99: train_loss=0.6416, val_loss=1.2017, val_acc=0.7300
Epoch 100: train_loss=0.6283, val_loss=1.1980, val_acc=0.7300
Epoch 101: train_loss=0.6269, val_loss=1.1963, val_acc=0.7280
Epoch 102: train_loss=0.6440, val_loss=1.1937, val_acc=0.7260
Epoch 103: train_loss=0.6339, val_loss=1.1900, val_acc=0.7220
Epoch 104: train_loss=0.6447, val_loss=1.1865, val_acc=0.7200
Epoch 105: train_loss=0.6104, val_loss=1.1843, val_acc=0.7180
Epoch 106: train_loss=0.5933, val_loss=1.1819, val_acc=0.7180
Epoch 107: train_loss=0.6324, val_loss=1.1786, val_acc=0.7140
Epoch 108: train_loss=0.6168, val_loss=1.1766, val_acc=0.7140
Epoch 109: train_loss=0.5861, val_loss=1.1741, val_acc=0.7140
Epoch 110: train_loss=0.5797, val_loss=1.1711, val_acc=0.7200
Epoch 111: train_loss=0.5935, val_loss=1.1695, val_acc=0.7200
Epoch 112: train_loss=0.5889, val_loss=1.1666, val_acc=0.7180
Epoch 113: train_loss=0.5694, val_loss=1.1637, val_acc=0.7220
Epoch 114: train_loss=0.5557, val_loss=1.1592, val_acc=0.7240
Epoch 115: train_loss=0.5577, val_loss=1.1544, val_acc=0.7180
Epoch 116: train_loss=0.5594, val_loss=1.1510, val_acc=0.7160
Epoch 117: train_loss=0.5736, val_loss=1.1478, val_acc=0.7200
Epoch 118: train_loss=0.5531, val_loss=1.1466, val_acc=0.7220
Epoch 119: train_loss=0.5527, val_loss=1.1469, val_acc=0.7240
Epoch 120: train_loss=0.5474, val_loss=1.1474, val_acc=0.7200
Epoch 121: train_loss=0.5532, val_loss=1.1460, val_acc=0.7180
Epoch 122: train_loss=0.5559, val_loss=1.1442, val_acc=0.7220
Epoch 123: train_loss=0.5716, val_loss=1.1423, val_acc=0.7200
Epoch 124: train_loss=0.5538, val_loss=1.1412, val_acc=0.7160
Epoch 125: train_loss=0.5609, val_loss=1.1376, val_acc=0.7140
Epoch 126: train_loss=0.5544, val_loss=1.1328, val_acc=0.7100
Epoch 127: train_loss=0.5961, val_loss=1.1283, val_acc=0.7100
Epoch 128: train_loss=0.5339, val_loss=1.1242, val_acc=0.7140
Epoch 129: train_loss=0.5391, val_loss=1.1216, val_acc=0.7180
Epoch 130: train_loss=0.5523, val_loss=1.1181, val_acc=0.7180
Epoch 131: train_loss=0.5109, val_loss=1.1164, val_acc=0.7160
Epoch 132: train_loss=0.5188, val_loss=1.1149, val_acc=0.7140
Epoch 133: train_loss=0.4707, val_loss=1.1130, val_acc=0.7120
Epoch 134: train_loss=0.5281, val_loss=1.1111, val_acc=0.7160
Epoch 135: train_loss=0.4890, val_loss=1.1083, val_acc=0.7220
Epoch 136: train_loss=0.5060, val_loss=1.1066, val_acc=0.7220
Epoch 137: train_loss=0.5160, val_loss=1.1063, val_acc=0.7220
Epoch 138: train_loss=0.5273, val_loss=1.1067, val_acc=0.7220
Epoch 139: train_loss=0.5014, val_loss=1.1069, val_acc=0.7220
Epoch 140: train_loss=0.4342, val_loss=1.1060, val_acc=0.7240
Epoch 141: train_loss=0.5184, val_loss=1.1034, val_acc=0.7200
Epoch 142: train_loss=0.4898, val_loss=1.0989, val_acc=0.7160
Epoch 143: train_loss=0.4789, val_loss=1.0960, val_acc=0.7160
Epoch 144: train_loss=0.4595, val_loss=1.0940, val_acc=0.7200
Epoch 145: train_loss=0.5084, val_loss=1.0916, val_acc=0.7220
Epoch 146: train_loss=0.4837, val_loss=1.0892, val_acc=0.7220
Epoch 147: train_loss=0.4880, val_loss=1.0865, val_acc=0.7220
Epoch 148: train_loss=0.4615, val_loss=1.0849, val_acc=0.7220
Epoch 149: train_loss=0.5101, val_loss=1.0842, val_acc=0.7180
Epoch 150: train_loss=0.5104, val_loss=1.0855, val_acc=0.7180
Epoch 151: train_loss=0.4651, val_loss=1.0879, val_acc=0.7200
Epoch 152: train_loss=0.4985, val_loss=1.0905, val_acc=0.7160
Epoch 153: train_loss=0.4455, val_loss=1.0897, val_acc=0.7120
Epoch 154: train_loss=0.4684, val_loss=1.0864, val_acc=0.7120
Epoch 155: train_loss=0.4523, val_loss=1.0817, val_acc=0.7140
Epoch 156: train_loss=0.4708, val_loss=1.0768, val_acc=0.7200
Epoch 157: train_loss=0.4767, val_loss=1.0729, val_acc=0.7240
Epoch 158: train_loss=0.4154, val_loss=1.0719, val_acc=0.7180
Epoch 159: train_loss=0.4771, val_loss=1.0722, val_acc=0.7140
Epoch 160: train_loss=0.4674, val_loss=1.0750, val_acc=0.7120
Epoch 161: train_loss=0.4481, val_loss=1.0788, val_acc=0.7160
Epoch 162: train_loss=0.5092, val_loss=1.0801, val_acc=0.7120
Epoch 163: train_loss=0.4337, val_loss=1.0793, val_acc=0.7120
Epoch 164: train_loss=0.4648, val_loss=1.0750, val_acc=0.7180
Epoch 165: train_loss=0.4570, val_loss=1.0693, val_acc=0.7200
Epoch 166: train_loss=0.4514, val_loss=1.0642, val_acc=0.7160
Epoch 167: train_loss=0.4373, val_loss=1.0611, val_acc=0.7140
Epoch 168: train_loss=0.4447, val_loss=1.0606, val_acc=0.7100
Epoch 169: train_loss=0.4884, val_loss=1.0627, val_acc=0.7100
Epoch 170: train_loss=0.4166, val_loss=1.0652, val_acc=0.7100
Epoch 171: train_loss=0.4236, val_loss=1.0698, val_acc=0.7100
Epoch 172: train_loss=0.4158, val_loss=1.0730, val_acc=0.7040
Epoch 173: train_loss=0.4337, val_loss=1.0730, val_acc=0.7100
Epoch 174: train_loss=0.4315, val_loss=1.0695, val_acc=0.7100
Epoch 175: train_loss=0.4652, val_loss=1.0650, val_acc=0.7060
Epoch 176: train_loss=0.4231, val_loss=1.0597, val_acc=0.7080
Epoch 177: train_loss=0.4653, val_loss=1.0561, val_acc=0.7120
Epoch 178: train_loss=0.4396, val_loss=1.0533, val_acc=0.7140
Epoch 179: train_loss=0.4143, val_loss=1.0518, val_acc=0.7140
Epoch 180: train_loss=0.4108, val_loss=1.0518, val_acc=0.7100
Epoch 181: train_loss=0.4566, val_loss=1.0522, val_acc=0.7120
Epoch 182: train_loss=0.4133, val_loss=1.0531, val_acc=0.7060
Epoch 183: train_loss=0.4593, val_loss=1.0530, val_acc=0.7080
Epoch 184: train_loss=0.4466, val_loss=1.0515, val_acc=0.7140
Epoch 185: train_loss=0.4333, val_loss=1.0497, val_acc=0.7120
Epoch 186: train_loss=0.3914, val_loss=1.0468, val_acc=0.7160
Epoch 187: train_loss=0.4090, val_loss=1.0459, val_acc=0.7200
Epoch 188: train_loss=0.3847, val_loss=1.0455, val_acc=0.7160
Epoch 189: train_loss=0.4231, val_loss=1.0475, val_acc=0.7160
Epoch 190: train_loss=0.4056, val_loss=1.0503, val_acc=0.7100
Epoch 191: train_loss=0.4440, val_loss=1.0518, val_acc=0.7120
Epoch 192: train_loss=0.3762, val_loss=1.0497, val_acc=0.7080
Epoch 193: train_loss=0.3971, val_loss=1.0451, val_acc=0.7120
Epoch 194: train_loss=0.4228, val_loss=1.0420, val_acc=0.7140
Epoch 195: train_loss=0.3966, val_loss=1.0395, val_acc=0.7180
Epoch 196: train_loss=0.4390, val_loss=1.0358, val_acc=0.7180
Epoch 197: train_loss=0.3790, val_loss=1.0323, val_acc=0.7160
Epoch 198: train_loss=0.3897, val_loss=1.0318, val_acc=0.7160
Epoch 199: train_loss=0.4000, val_loss=1.0327, val_acc=0.7160
Epoch 200: train_loss=0.4129, val_loss=1.0352, val_acc=0.7160

Final test accuracy: 0.7070
